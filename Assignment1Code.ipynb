{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "# Group 13\n",
    "Mathieu Mailhot - Isabel Lougheed - Frank-Lucas Pantazis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- CKD: 28 numerical features, 1 target binary classification variable (\"Normal\" / \"battery\")\n",
    "- Battery: 32 real-valued features, 2 classes (\"Normal\" / \"Defective\")\n",
    "\"\"\"\n",
    "\n",
    "# load data sets\n",
    "\n",
    "# Calculate cross entropy or/ Information Gain for all the data without the threshold\n",
    "\n",
    "# statistical analysis on the datasets\n",
    "\n",
    "# - normalize\n",
    "\n",
    "# models: all features, selective features based on statistical analysis (dropping features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data sets\n",
    "df_CKD = pd.read_csv(\"CKD.csv\")\n",
    "df_battery = pd.read_csv(\"Battery_Dataset.csv\")\n",
    "\n",
    "# Convert \"CKD\" to 1 and \"Normal\" to 0\n",
    "df_CKD[\"label\"] = df_CKD[\"label\"].replace({\"CKD\": 1, \"Normal\": 0})\n",
    "# Convert \"Defective\" to 1 and \"Normal\" to 0\n",
    "df_battery[\"label\"] = df_battery[\"label\"].replace({\"Defective\": 1, \"Normal\": 0})\n",
    "\n",
    "# Convert to a numpy array\n",
    "CKD_data = df_CKD.to_numpy()\n",
    "battery_data = df_battery.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Analysis Block\n",
    "\n",
    "# Class for the analysis\n",
    "class Stat_analysis:\n",
    "    def __init__(self, data, name, save_folder):\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        self.save_folder = save_folder\n",
    "        self.feature_distribution()\n",
    "        self.class_distrubution()\n",
    "\n",
    "    # Function to create a distribution for each feature\n",
    "    def feature_distribution(self):\n",
    "        for i in range(self.data.shape[1] - 2): # remove 1 and last column as we do not need them for the distribution of the features\n",
    "            feature_num = i + 1\n",
    "\n",
    "            plt.hist(self.data[:,feature_num], bins=20, edgecolor=\"black\")\n",
    "            plt.xlabel(\"Value\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.title(f\"{self.name} Distribution of Feature {feature_num}\")\n",
    "\n",
    "            filename = os.path.join(self.save_folder, f\"{self.name}_feature{feature_num}_distribution.png\")\n",
    "            plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "    \n",
    "    # Function to create a distribution for the class\n",
    "    def class_distrubution(self):\n",
    "        my_bins = [-0.5, 0.5, 1.5]\n",
    "        class_0 = \"Normal\"\n",
    "        if self.name == \"CKD\":\n",
    "            class_1 = \"CKD\"\n",
    "        else:\n",
    "            class_1 = \"Defective\"\n",
    "\n",
    "        plt.hist(self.data[:,self.data.shape[1] - 1], bins=my_bins, edgecolor=\"black\", align=\"mid\", rwidth=0.6)\n",
    "        plt.xticks([0, 1], [class_0, class_1])\n",
    "        plt.xlabel(\"Category\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(f\"{self.name} Distribution of Class\")\n",
    "\n",
    "        filename = os.path.join(self.save_folder, f\"{self.name}_class_distribution.png\")\n",
    "        plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "# Perform the stastical analysis\n",
    "CKD_stat = Stat_analysis(CKD_data, \"CKD\", \"CKD_distribution\")\n",
    "battery_stat = Stat_analysis(battery_data, \"Battery\", \"Battery_distribution\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,  dataframe, data_array, description:str = None):\n",
    "        \n",
    "        # Hyperparameter variables for Adam Gradient Descent Algorithm\n",
    "        self.max_iteration = 2000\n",
    "        self.tolerance = 10**-6 #3\n",
    "        self.step_size = 0.03\n",
    "        self.b_1 = 0.95\n",
    "        \n",
    "        # Data variables\n",
    "        self.dataframe = dataframe\n",
    "        self.data_array = data_array\n",
    "        self.description = description\n",
    "        \n",
    "        # Training and Validation variables\n",
    "        self.accuracy_arr = []\n",
    "        self.avg_accuracy = 0\n",
    "        \n",
    "        self.weigth_arr = []\n",
    "        self.avg_weigth = 0\n",
    "\n",
    "        self.avg_loss_per_iteration = []\n",
    "        self.figure = []\n",
    "    \n",
    "    def normalize(self, normalize_by_max:bool, standardize:bool): \n",
    "        # Normalize the dataset\n",
    "        # I think you should only normalize by max OR standardize, and I think standardizing would produce better results\n",
    "\n",
    "        # Separate features and target\n",
    "        df = self.dataframe # make sure data is a data frame\n",
    "        features = df.drop(['ID', 'label'], axis=1)\n",
    "        target = df['label']\n",
    "\n",
    "        df_norm = df # if normalize_by_max = false and standardize = false, will return original df\n",
    "\n",
    "        if normalize_by_max:\n",
    "            # normalizing by extremas, scales to [0,1]\n",
    "            # ensures data is well-conditioned\n",
    "            features_normalized = (features - features.min())/(features.max() - features.min())\n",
    "            df_norm = pd.concat([df[['ID']], features_normalized, df[['label']]], axis=1)\n",
    "\n",
    "        if standardize:\n",
    "            # z score normalization, good for gaussian distributions\n",
    "            # forces std 1 and mean 0\n",
    "            features_standardized = (features - features.mean())/features.std()\n",
    "            df_norm = pd.concat([df[['ID']], features_standardized, df[['label']]], axis=1)\n",
    "\n",
    "        # returns a pandas dataframe\n",
    "        return df_norm\n",
    "    \n",
    "    def crossValidation(self, folds:int,learning_rate = None, tolerance = None, beta = None): \n",
    "        # Split dataset into folds\n",
    "        # I think that self.data should only include non test data\n",
    "\n",
    "        # hyperparameters Change\n",
    "        if (learning_rate):\n",
    "            self.step_size = learning_rate\n",
    "        if (tolerance):\n",
    "            self.tolerance = tolerance\n",
    "        if (beta):\n",
    "            self.b_1 = beta\n",
    "\n",
    "        data = self.data_array[:,1:] # removing first column (ID)\n",
    "        fold_size = len(data) // folds\n",
    "        validation_experiments = []\n",
    "        train_experiments = []\n",
    "\n",
    "        \n",
    "\n",
    "        for i in range(folds):\n",
    "            if i==(folds-1):\n",
    "                # how should i deal with uneven split ??? is it okay for the last fold to be smaller?\n",
    "                validation_fold = data[(i*fold_size):]  #df.iloc[(i*fold_size):(len(df))]\n",
    "                train_fold = data[:(i*fold_size)] #pd.concat([df.iloc[:(i*fold_size)], df.iloc[(len(df)):]])\n",
    "\n",
    "            else:\n",
    "                validation_fold = data[(i*fold_size):(i*fold_size + fold_size)] #df.iloc[(i*fold_size):(i*fold_size + fold_size)]\n",
    "                train_fold = np.vstack([data[:(i*fold_size)], data[(i*fold_size + fold_size):]]) #pd.concat([df.iloc[:(i*fold_size)], df.iloc[(i*fold_size + fold_size):]])\n",
    "            validation_experiments.append(validation_fold)\n",
    "            train_experiments.append(train_fold)\n",
    "\n",
    "        # Train\n",
    "        avg_error1 = 0\n",
    "        avg_error2 = 0\n",
    "        \n",
    "        for i in range(folds):\n",
    "            # train each training set with fit() to get weights\n",
    "            train_experiment = train_experiments[i]\n",
    "            w = self.fit(train_experiment)\n",
    "            self.weigth_arr.append(w.tolist())\n",
    "            # get errors \n",
    "            validation_experiment = validation_experiments[i]\n",
    "            error1,error2 = self.Accu_eval(w, validation_experiment) \n",
    "            \n",
    "            avg_error1 += error1\n",
    "            avg_error2 += error2\n",
    "        \n",
    "        self.avg_weigth = np.mean(np.array(self.weigth_arr),axis = 0)\n",
    "        \n",
    "\n",
    "        avg_error1 = avg_error1/folds\n",
    "        avg_error2 = avg_error2/folds\n",
    "        \n",
    "        #print(\"MSE error:\", avg_error1)\n",
    "        #print(\"Accuracy error:\", avg_error2)\n",
    "        for pos in range(len(self.avg_loss_per_iteration)):\n",
    "            num = self.avg_loss_per_iteration[pos][0]\n",
    "            item = self.avg_loss_per_iteration[pos][1]\n",
    "            self.figure.append(item/num)\n",
    "        \n",
    "        return (avg_error1,avg_error2)\n",
    "\n",
    "    def fit(self,train_data):\n",
    "        \n",
    "        # Trains using gradient descent: Lecture 5 slide 55-58\n",
    "\n",
    "        w_prev = np.ones(train_data.shape[1])*1 # (number of columns of train_data - 1 to remove label, + 1 to account for bias term)\n",
    "        m = 0\n",
    "        correct_prediction = 0\n",
    "\n",
    "        for epoch in range(self.max_iteration):\n",
    "            delta = np.zeros(len(w_prev))\n",
    "            correct_prediction = 0\n",
    "            for row_i in train_data:\n",
    "                y_i = row_i[-1] # extracting value\n",
    "                x_i = row_i.copy() # extracting features\n",
    "                x_i[-1] = 1 # because of bias term\n",
    "                delta += x_i*(y_i-self.predict(w_prev,x_i))\n",
    "                if (y_i-self.predict(w_prev,x_i)<=0.5):\n",
    "                    correct_prediction+=1\n",
    "        \n",
    "\n",
    "            #m = self.b_1 * m + (1-self.b_1) * delta\n",
    "            w_new = w_prev + self.step_size/(1+epoch) * delta\n",
    "            #w_new = w_prev + self.step_size * m  # to be able to reach better precision need to devide step size by num iteration\n",
    "       \n",
    "            w_diff = np.linalg.norm(w_new - w_prev)\n",
    "            \n",
    "            w_prev = w_new\n",
    "            if (len(self.avg_loss_per_iteration)<=epoch):\n",
    "                self.avg_loss_per_iteration.append([1,1-correct_prediction/len(train_data)])\n",
    "               \n",
    "            else:\n",
    "                self.avg_loss_per_iteration[epoch][0] +=1 \n",
    "                self.avg_loss_per_iteration[epoch][1]+= 1-correct_prediction/len(train_data)\n",
    "            if (w_diff**2<self.tolerance):\n",
    "                return w_new\n",
    "            \n",
    "       \n",
    "        \n",
    "        # Means there was a problem\n",
    "        print(\"Not converged\", w_new , w_diff)\n",
    "        return w_new\n",
    "\n",
    "    \n",
    "    def predict(self,w,x):\n",
    "        # Predicts output: function at bottom Lecture 5 slide 44\n",
    "        a = w.T @ x\n",
    "        return 1/(1+np.exp(-np.clip(a, -500, 500)))\n",
    "\n",
    "    def Accu_eval(self,w,validate_data): # Used MSE\n",
    "        # Validation\n",
    "        error = 0\n",
    "        correct_prediction = 0\n",
    "        for row_i in validate_data:\n",
    "            y_i = row_i[-1] # extracting value\n",
    "            x_i = row_i.copy() # extracting features\n",
    "            x_i[-1] = 1\n",
    "            \n",
    "            error += (y_i-self.predict(w,x_i))**2 \n",
    "            if ((y_i-self.predict(w,x_i))<=0.5):\n",
    "                correct_prediction+=1\n",
    "        \n",
    "        return (error/len(validate_data), 1-correct_prediction/len(validate_data))\n",
    "\n",
    "    def hyperparameterAnalysis(self,folds):\n",
    "        if (False):\n",
    "\n",
    "            i = 0\n",
    "            for a in np.arange(0.001,0.011,0.001):\n",
    "                self.clear()\n",
    "                plt.figure(i)\n",
    "                for b in np.arange(0.9,1,0.01):\n",
    "                    \n",
    "                    self.clear()   \n",
    "                    self.crossValidation(folds,learning_rate=a,beta=b)\n",
    "                    self.addPlot(f\"beta = {round(b,3)}\")\n",
    "                plt.title(f'Analysis of beta when alpha = {round(a,4)}') \n",
    "                plt.xlabel('Iterations')\n",
    "                plt.ylabel('Accuracy')\n",
    "                plt.grid(True)\n",
    "                plt.legend()\n",
    "                plt.show() \n",
    "                i+=1\n",
    "        else:\n",
    "            plt.figure(1)\n",
    "            i=1\n",
    "            for a in np.arange(0.01,0.11,0.01):\n",
    "                self.clear()\n",
    "                print(f\"plot {i}\")\n",
    "                i+=1\n",
    "                self.crossValidation(folds,learning_rate=a)\n",
    "                self.addPlot(f\"alpha = {round(a,3)}\")\n",
    "                \n",
    "            plt.title(f'Analysis of alpha') \n",
    "            plt.xlabel('Iterations')\n",
    "            plt.ylabel('1-Accuracy')\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            plt.show() \n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "    def addPlot(self,legend_label):\n",
    "        x = np.array(range(len(self.avg_loss_per_iteration)))\n",
    "        y = self.figure\n",
    "        plt.plot(x, y, label=legend_label)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.accuracy_arr = []\n",
    "        self.avg_accuracy = 0\n",
    "        self.figure =[]\n",
    "        self.weigth_arr = []\n",
    "        self.avg_weigth = 0\n",
    "\n",
    "        self.avg_loss_per_iteration = []\n",
    "\n",
    "class Analysis:\n",
    "     def __init__(self, model, descriptor):\n",
    "         print(descriptor)\n",
    "\n",
    "         df_norm = model.normalize(True,False)\n",
    "         df_norm.drop(['ID', 'label'], axis=1)\n",
    "         norm_model = Model(df_norm, df_norm.to_numpy(),\"\\tNormalised\")\n",
    "\n",
    "         df_stand = model.normalize(False, True)\n",
    "         df_stand.drop(['ID', 'label'], axis=1)\n",
    "         stand_model = Model(df_norm, df_norm.to_numpy(),\"\\tStandardized\")\n",
    "\n",
    "         norm_model.crossValidation(10)\n",
    "         stand_model.crossValidation(10)\n",
    "         \n",
    "     \"\"\"     for b in np.arange(0.9,1,0.01):\n",
    "            self.clear()\n",
    "            self.crossValidation(folds,beta=b)\n",
    "            self.addPlot(f\"beta = {round(b,2)}\")\n",
    "        plt.title('Analysis of beta')    \n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\"\"\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition data into training and testing\n",
    "\n",
    "# Shuffle data\n",
    "df_CKD = df_CKD.sample(frac = 1, random_state = 2).reset_index(drop=True)\n",
    "df_battery = df_battery.sample(frac = 1, random_state = 2).reset_index(drop=True)\n",
    "\n",
    "# Taking approximately 90% of data for training and validation\n",
    "non_testing_size_ckd = 10*(int(0.9*len(df_CKD))//10) # make size of training/validation set dividible for 10 so it is suitable for a 10 fold cross validation\n",
    "train_df_CKD = df_CKD.iloc[:non_testing_size_ckd]\n",
    "train_CKD_data = train_df_CKD.to_numpy()\n",
    "\n",
    "non_testing_size_battery = 10*(int(0.9*len(df_battery))//10) # make size of training/validation set dividible for 10 so it is suitable for a 10 fold cross validation\n",
    "train_df_battery = df_battery.iloc[:non_testing_size_battery]\n",
    "train_battery_data = train_df_battery.to_numpy()\n",
    "\n",
    "# Taking 10% of data for testing\n",
    "test_df_CKD = df_CKD.iloc[non_testing_size_ckd:]\n",
    "test_battery_CKD = test_df_CKD.to_numpy()\n",
    "\n",
    "test_df_battery = df_battery.iloc[non_testing_size_battery:]\n",
    "test_battery_data = test_df_battery.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number of normalized dataset :  16.27262719478567\n",
      "Condition number of standardized dataset :  1.6816260377340257\n",
      "---------------------------------------------------------\n",
      "Error after training normalized dataset :  (0.210450232012577, 0.1818181818181818) [[-1.0048813374733188, 2.6377412036813093, -0.007996131844956416, -0.05452705166663903, 0.005846232051751571, 0.07727522004708666, -0.10734127664784125, -0.2565893287077645, -0.28306570402740105, -0.06039017580494417, 0.240426446345536, 0.32781327746460753, 0.03921820817103171, 0.1383196160171749, -0.19459140151073073, 0.12790357976743422, -0.04911595609879928, 0.2741564230417657, 0.09470480803781696, -0.021311530092273632, 0.2579899725868832, -0.4559351789976207, -0.3314641490709454, -0.043395853264656316, 0.0899030806921126, -0.09201345620629266, -0.015798442651862837, 0.24616959253155365, -0.7415136553399541], [-0.896992412713136, 2.5735032225511487, 0.07817387536551605, 0.004076857681201121, -0.1393306290806198, 0.07717799685793407, -0.07734655442177849, -0.22512925779441878, -0.3813052340971341, -0.142590987448842, 0.570431923322389, 0.2751174668324633, 0.03548620367029553, 0.022355264611219765, -0.17441350533080727, 0.1553410163607486, -0.15932791813427555, 0.32297743008825336, 0.18816228536497948, 0.17603817275189723, 0.16126805499874644, -0.364705225386923, -0.2784740651568212, 0.12584408824508095, -0.04551286016371199, -0.06033625475697195, -0.07621711363508528, 0.184640264647639, -0.8524980526472715], [-0.8188198742183149, 2.408680576709519, -0.08885744174464709, 0.09393288533951362, -0.22655693224589646, 0.10367699273597547, -0.20854713264477331, -0.20270082027192807, -0.19378227648121543, -0.23804957162173707, 0.435946809227956, 0.46194546194959596, 0.09007162209279958, -0.02472240223203364, -0.10141490596692108, -0.0434146593519873, 0.10511636648005541, 0.2378836358611769, 0.2032548885770723, 0.050940815576433, 0.2200442467031455, -0.638570059158368, -0.09138641927176026, 0.1298893499208081, 0.0898988906855294, -0.22890371371844856, 0.08532914848402429, 0.2151039005210626, -0.8854930742107063], [-0.9062730054533122, 2.606290949456502, -0.13018985045062514, -0.016484742914947864, -0.06324128719999915, 0.02892945587941005, -0.05957461082455487, -0.1677788560031346, -0.2916643293924669, -0.1846664723056951, 0.4346000374889243, 0.32432894533108414, 0.023089610589220818, 0.13257200151731136, -0.17145172517684046, 0.19742970779826421, 0.05131345541061723, 0.23684828307991104, 0.032895900360814724, 0.048753239489813596, 0.13986659632380483, -0.5186522684665174, -0.21160586605156698, 0.042505633314075725, 0.0923206372074603, 0.27324488723374, -0.15443483355480314, 0.14865382991055437, -0.8867031234146763], [-0.7294066560927296, 2.559786145123313, -0.0038580287671388875, -0.15671762601934514, -0.00993794021269769, 0.18357039554716278, -0.2030735964269291, -0.28643181752648766, -0.32841106256992514, -0.10586056255100634, 0.4426807819490218, 0.2350910449049422, -0.01214052267556078, -0.03038832106449419, -0.252641241899487, 0.11871677489831275, 0.03241894571833292, 0.22358059535233588, 0.15845766461813893, 0.20338243218367744, 0.17727368350308634, -0.49224714665723773, -0.24788914248966723, 0.11552616854588905, 0.0950369156710489, -0.09278289768880303, -0.11620622108241017, 0.2651813896562088, -0.76444323479736], [-0.7560326521821175, 2.5871808418801447, -0.030998008735978456, 0.12454064183254743, -0.03590542782341805, -0.02311658228670004, -0.18375374844440984, -0.2767350825809889, -0.20931827812944548, -0.24235663227793997, 0.2891114546873315, 0.380626614679612, -0.13766140592303247, 0.07258861871098447, -0.19823459430195176, 0.21537979286388814, -0.08280076388080905, 0.09083658948309507, 0.06819672193824544, 0.08155664651485348, 0.29685237917675333, -0.4323077005262234, -0.3704200079756132, 0.14413890393436796, 0.013110539472409652, 0.17568632127190076, -0.04397593298307732, 0.2098322049934312, -0.8411699938363136], [-0.8925584459631708, 2.5713242407074715, 0.05027256553312151, -0.06834368973152766, -0.1842746818179677, 0.2521149899708355, -0.2625315184997717, -0.09206120252759745, -0.24637219378979272, 0.06367925468110572, 0.1805446670765311, 0.4491577359657466, 0.04374423815424456, -0.07834267059989897, -0.23280770645950466, 0.08036293388136745, 0.24002782839759434, 0.17992280392997453, 0.05835889123819968, 0.0635775554021553, 0.06995615059557612, -0.4299835457793754, -0.19584879256468246, -0.037040392631687895, -0.04663405233832859, -0.03636632782243405, 0.03594675137877984, 0.2180265618939338, -0.7699564855313639], [-0.787724287125839, 2.5560276582774497, 0.041440306842493654, 0.11471907936840033, -0.16572473172870825, 0.21352201983250735, -0.3173901000551666, -0.3305213354570524, -0.28803003592287557, -0.029410299097685496, 0.3879163538401637, 0.4693396561743124, 0.08832209447614842, -0.10338284352540597, -0.0070606376482229465, 0.06892153540304291, 0.023442233378669932, 0.26470236499771127, -0.11525709077815945, -0.012169879889355643, 0.32467474379999317, -0.3964878322579321, -0.4443228820181085, -0.038389975558051646, 0.06801675236902188, 0.04052645003564397, -0.13584311483206035, 0.19361866831980698, -0.8474419001544866], [-0.9754287145762345, 2.477861197331098, 0.05973201884596266, -0.038241733109958057, 0.02256276293656165, 0.15085354597568335, -0.06101610671003518, -0.31779524265470516, -0.3190393935468003, 0.018946398338677447, 0.2396975126503538, 0.29666720990753104, 0.010103283861038245, 0.009512706178860473, -0.20779978879765218, 0.053789285194926144, 0.07392714506490067, 0.19628108264954483, 0.16396149747800307, 0.01964875059801205, 0.31992824474877773, -0.5206463264513121, -0.3007640284034809, 0.042351159786876647, -0.02299384360449404, -0.0051845446472156085, 0.05229989486435204, 0.19411887847950385, -0.7917802424589672], [-0.9095230695741049, 2.533849918629489, -0.10208746222630982, -0.13950947463566504, -0.04569986680234419, -0.071316756938474, -0.11621140340490967, -0.36713831594706814, -0.06478540812010194, -0.08847448033756705, 0.21687681438664383, 0.4877937963528028, -0.14846793447912837, 0.1510273536075555, -0.1580992235884554, 0.17287977214116496, 0.07412745605298562, 0.03532911670160422, 0.042708432107631034, 0.04211154505804978, 0.29959272095621564, -0.4117594744396529, -0.15003201804741198, 0.020174503830501737, 0.1833384598759361, 0.11217587438164303, 0.1735274855817246, 0.15184794391949555, -0.8347254088680038]]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'i' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10768\\1764445658.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#print(\"Error after training original dataset : \", ckd_model.crossValidation(10))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error after training normalized dataset : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckd_model_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrossValidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckd_model_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweigth_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mckd_model_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameterAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10768\\1094041282.py\u001b[0m in \u001b[0;36mhyperparameterAnalysis\u001b[1;34m(self, folds)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"plot {i}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrossValidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddPlot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"alpha = {round(a,3)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'i' referenced before assignment"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing whole model for CKD data with cross validation\n",
    "\n",
    "\n",
    "ckd_model = Model(df_CKD, CKD_data, \"This is the model for the CKD dataset\")\n",
    "features_ckd = df_CKD.drop(['ID', 'label'], axis=1)\n",
    "\n",
    "def condition_number(features):\n",
    "    A = features.to_numpy()\n",
    "    U, S, V = np.linalg.svd(A, full_matrices=False)\n",
    "    condition_num = np.max(S) / np.min(S[np.nonzero(S)])\n",
    "    return condition_num\n",
    "\n",
    "# normalize data\n",
    "df_norm = ckd_model.normalize(True, False)\n",
    "features_ckd_norm = df_norm.drop(['ID', 'label'], axis=1)\n",
    "ckd_model_norm = Model(df_norm, df_norm.to_numpy())\n",
    "\n",
    "# standardize data\n",
    "df_stand = ckd_model.normalize(False, True)\n",
    "features_ckd_stand = df_stand.drop(['ID', 'label'], axis=1)\n",
    "ckd_model_stand = Model(df_stand, df_stand.to_numpy())\n",
    "\n",
    "#print(\"Condition number of original dataset : \", condition_number(features_ckd))\n",
    "print(\"Condition number of normalized dataset : \", condition_number(features_ckd_norm))\n",
    "print(\"Condition number of standardized dataset : \", condition_number(features_ckd_stand))\n",
    "print(\"---------------------------------------------------------\")\n",
    "#print(\"Error after training original dataset : \", ckd_model.crossValidation(10))\n",
    "print(\"Error after training normalized dataset : \", ckd_model_norm.crossValidation(10), ckd_model_norm.weigth_arr)\n",
    "ckd_model_norm.hyperparameterAnalysis(10)\n",
    "\n",
    "\n",
    "#print(\"Error after training standardized dataset : \", ckd_model_stand.crossValidation(10),ckd_model_stand.avg_weigth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number of normalized dataset :  17.632795820381176\n",
      "Condition number of standardized dataset :  1.6891992219130851\n",
      "---------------------------------------------------------\n",
      "Error after training normalized dataset :  (0.08785117523977486, 0.06283105022831052) [ 5.63873527  5.39081415 -0.08106489  0.06558979 -0.13812895 -0.26927749\n",
      " -0.85114703 -0.64135261 -0.41876286 -0.08583654 -0.13542509 -0.3510816\n",
      " -0.06293764 -0.49744002 -0.46545152 -0.54436782 -0.16641081 -0.36709961\n",
      " -0.16556723 -0.23098716 -0.04263766  0.01374884  0.02663294  0.01554327\n",
      "  0.04290744 -0.55748976  0.04840302 -0.56473875 -0.4236164  -0.27490406\n",
      " -0.30922373 -0.40976104 -1.67216339]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10768\\2831220081.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#print(\"Error after training original dataset : \", battery_model.crossValidation(10))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error after training normalized dataset : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbattery_model_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrossValidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbattery_model_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg_weigth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mbattery_model_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameterAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error after training standardized dataset : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbattery_model_stand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrossValidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbattery_model_stand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg_weigth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10768\\1937936271.py\u001b[0m in \u001b[0;36mhyperparameterAnalysis\u001b[1;34m(self, folds)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrossValidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddPlot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"alpha = {round(a,3)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10768\\1937936271.py\u001b[0m in \u001b[0;36mcrossValidation\u001b[1;34m(self, folds, learning_rate, tolerance, beta)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;31m# train each training set with fit() to get weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mtrain_experiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_experiments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_experiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweigth_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;31m# get errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10768\\1937936271.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_data)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mrow_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[0my_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# extracting value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                 \u001b[0mx_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# extracting features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m                 \u001b[0mx_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;31m# because of bias term\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mx_i\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_i\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_prev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABA2klEQVR4nO3de3Rc5X3/+8+zZ0YX3wT4ItuxEE7CxWBCiJwEOXUuUJSakKS/pKlDToA0uI1roMdxcvKL4/YHYXXV/Hqo63QFm7ByITRN8OkBepoTt4m6isHETRsc8YMASTiJQcbIGBuw5Iukmb2f88fM3rP3zB5JMxp5gvb7tZbWzOy9Z/TM1lj6+Hm+z7ONtdYKAACgQZxGNwAAACQbYQQAADQUYQQAADQUYQQAADQUYQQAADQUYQQAADQUYQQAADQUYQQAADRUutENmAjP8/Tiiy9q9uzZMsY0ujkAAGACrLUaGhrS4sWL5TiV+z9eF2HkxRdfVEdHR6ObAQAAanDgwAEtWbKk4v7XRRiZPXu2pPybmTNnToNbAwAAJmJwcFAdHR3B3/FKXhdhxB+amTNnDmEEAIDXmfFKLChgBQAADUUYAQAADUUYAQAADUUYAQAADUUYAQAADUUYAQAADUUYAQAADUUYAQAADUUYAQAADVVTGNm+fbuWLl2qlpYWdXV1ac+ePRWP3b17t4wxZV+/+MUvam40AACYPqoOIzt37tSGDRu0efNm9fX1adWqVVq9erX6+/vHfN4vf/lLDQwMBF/nnntuzY0GAADTR9VhZOvWrbrhhhu0du1aLVu2TNu2bVNHR4d27Ngx5vMWLFighQsXBl+pVKrmRgMAgOmjqgvljY6Oat++ffriF78Y2d7T06O9e/eO+dxLL71Uw8PDuvDCC/Xnf/7net/73lfx2JGREY2MjASPBwcHq2lmVY4dPaIHNv+tnFyLZi7O6ZX3fEjOiTs1c/aHlJuzQGr9ta654BqlndfFNQUBAHjdqeov7JEjR+S6rtrb2yPb29vbdejQodjnLFq0SHfffbe6uro0MjKiv//7v9cVV1yh3bt3693vfnfsc7Zs2aIvf/nL1TStZrv+7k6d1BVSWjpxKKf//I//Uz/reEqXPP+0/ldmodT6a51/5vl6x6J3nJb2AACQNDX9d7/0UsDW2oqXBz7//PN1/vnnB4+7u7t14MAB3XHHHRXDyKZNm7Rx48bg8eDgoDo6Ompp6rhyp7LBfeuk1aJhSZLr5ORqRClJJ7In9O2nvq3OOZ16b8d7p6QdAAAkVVVhZN68eUqlUmW9IIcPHy7rLRnLZZddpu985zsV9zc3N6u5ubmaptXMWlu6wb9T+JJeOP6C7njsDrXPaCeMAABQZ1UVsDY1Namrq0u9vb2R7b29vVq5cuWEX6evr0+LFi2q5ltPGWPjH4c3n8qdkiQNu8Onp1EAACRI1cM0Gzdu1LXXXqsVK1aou7tbd999t/r7+7Vu3TpJ+SGWgwcP6t5775Ukbdu2Teecc44uuugijY6O6jvf+Y7uv/9+3X///fV9JzUqySKKzPEpJBPPevljS3tRAADApFUdRtasWaOjR4/qtttu08DAgJYvX65du3aps7NTkjQwMBBZc2R0dFSf//zndfDgQbW2tuqiiy7SD37wA1111VX1exdTwUh+VPFDiC2LLgAAYLJqKmBdv3691q9fH7vvnnvuiTz+whe+oC984Qu1fJvTo2yYxhQ2F3d48mKPBQAAk8e1aUqGXozCs4JKhmlIIwAA1F3iw0hpGYgJBY603MIxhBEAAKZK4sNIqeLsGquF5hVJkjc4kN9CASsAAHVHGClRrBmRUibfM+KNHi9sI4wAAFBvhJGyfGHKdlmvsEprbqT0YAAAMEmEkZIwEpyQUB2rd+q1/KHWPR0tAgAgUQgjJcIrsPo5xZ/ayyANAAD1l/gwUhowbNAlUtxTXPQMAADUW+LDSOncXieuZ8TSMwIAwFQhjJStM2LKDvFEzwgAAFOFMBITPnz+VF5/0TMAAFB/hJES4XVGCnflUTMCAMCUIYyUVbAWEogJFbAymwYAgCmT+DBSuqqq3zOS35dHzwgAAFMn8WGktGbEFB6Gg0dQwGoq15cAAIDaEEbKFxopu8sF8gAAmDqEkbKpvU5hc3GHF5pNQzABAKC+CCMlwgMxxeXgw8WshBEAAOqJMFIqmE1TvBvuDaFnBACA+kp8GCmNFuF1Rnz0jAAAMHUSH0ZMWbaIm9obqhkhjAAAUFeJDyPlyntGbNwUGwAAUBeEkRLFRc8sBawAAJwGhBFbsuhZMLW3yLOEEQAApkriw8hY0SJY9EzMpgEAYKokPoyU8WfThKb2RnpGQsWsAABg8hIfRkpn0xhbfkoiNSMeYQQAgHpKfBgpH3Upn9prS+bWAACA+kl8GClXnNpbXGeEYRoAAKYKYUQls2lKZtdIpQWshBEAAOqJMFJh1MVWWmeEMAIAQF0RRsoU1xnxI8hrp7LBXtYZAQCgvggjlYZpTHFXLjSDhp4RAADqizBSwsQUsEYQRgAAqCvCSJniKQmm9hpqRgAAmCqEkdLuD1u+OXKfMAIAQF0RRlQ6lTemZyS0lzACAEB9EUbKlNeMcKE8AACmDmGkRPjaNEHsCHWeWNEzAgBAPRFGKlybJtIbEtr705f26YMPflA/PfTTKW8aAABJkPgwYstqRvx1Roz8JUfCwWT3iz/Wc4PP6eEDD5+eBgIAMM0lPoyURRHrr8BqQ1N7i/v9AlZWYgUAoD4SH0bKxRWwFvlX8CWMAABQH4SRsnVG4k5J8SDP7xlhVg0AAHVBGCm9Ns04PSPMpgEAoL4IIyXiVl4N14x41IwAAFBXiQ8jpbNpTOGUWCNZU+wl8QU1IwzTAABQF4kPI6WMLQ8g0TDiFrYRRgAAqIfEh5HSqb1xp8SLKWD1uEYNAAB1kfgwEikICT32KhzC8AwAAPVFGCkzzjCNmNoLAEA9EUZKhAtYfdGaEWbTAABQT4kPI8FsmqAGZGLDNIQRAADqI/FhxGf8YZfg2jRFsT0jDNMAAFAXiQ8j/lReU5iya4KekWJ3SLiXhGEaAADqK/FhxGeCcFEoYB2vZoSeEQAA6oIwUggdfs+If0oiwzTh5eBFzwgAAPVUUxjZvn27li5dqpaWFnV1dWnPnj0Tet6Pf/xjpdNpvfWtb63l204Ja0sKWGPWGYkUs7IcPAAAdVV1GNm5c6c2bNigzZs3q6+vT6tWrdLq1avV398/5vOOHTum6667TldccUXNjZ1KfgGrGW+dEWpGAACoq6rDyNatW3XDDTdo7dq1WrZsmbZt26aOjg7t2LFjzOd95jOf0Sc+8Ql1d3fX3Nip4I/AlA7TeJGhmfB9loEHAKCeqgojo6Oj2rdvn3p6eiLbe3p6tHfv3orP+9a3vqVf//rXuuWWWyb0fUZGRjQ4OBj5mjr+bJqSAtbQEXHrjHBtGgAA6qOqMHLkyBG5rqv29vbI9vb2dh06dCj2Oc8++6y++MUv6h/+4R+UTqcn9H22bNmitra24Kujo6OaZlbFKjq1119nJFInErrvMkwDAEBd1VTAakz04nLW2rJtkuS6rj7xiU/oy1/+ss4777wJv/6mTZt07Nix4OvAgQO1NHNiCpnCn9ob1IyY+HVGLFN7AQCoq4l1VRTMmzdPqVSqrBfk8OHDZb0lkjQ0NKTHHntMfX19uummmyRJnufJWqt0Oq0f/ehHuvzyy8ue19zcrObm5mqaNmkmGHYpz2fRYMJy8AAA1FNVPSNNTU3q6upSb29vZHtvb69WrlxZdvycOXP05JNP6vHHHw++1q1bp/PPP1+PP/643vnOd06u9XXg9+j4YcSovIcnLKgVIYsAAFAXVfWMSNLGjRt17bXXasWKFeru7tbdd9+t/v5+rVu3TlJ+iOXgwYO699575TiOli9fHnn+ggUL1NLSUra9UYLRlgmGES6UBwBAfVUdRtasWaOjR4/qtttu08DAgJYvX65du3aps7NTkjQwMDDumiO/XeILWCthBVYAAOqr6jAiSevXr9f69etj991zzz1jPvfWW2/VrbfeWsu3nVKli55V4jG1FwCAukr8tWn88GGCOTPjDdMQQgAAqKfEh5FgqbOgZmTsU+KKqb0AANRT4sNIsWZkoj0jFLACAFBPhJGCoGdkvAJWFj0DAKCuEh9GgoLVCfaMsOgZAAD1lfgwUl4zMsFhGnpGAACoi8SHkfKaEdYZAQDgdCKMBBfKm+AwDQWsAADUFWGkkD0mOrWXAlYAAOqLMGKrm9pLASsAAPVFGFF1V+1lnREAAOqLMFIyTDPhAlaGaQAAqAvCiC1ZZ8ROsICVMAIAQF0QRgomWsBqqRkBAKCuCCNVXrWXqb0AANQXYcQ30Qvl+SGELAIAQF0QRoLwMbFhGh89IwAA1AdhpGCi64z4CCMAANQHYaSkZ2Sip8QLwgsAAJgMwkigyp4RpvYCAFAXhBFF1xkZbwVWAABQX4SRQHXDNNSMAABQH4SRspqRCQ7T5IanpDUAACQNYSTg93SEwoi1ah6N7wGxxw9PfZMAAEgAwkghfFjrFh4XT8kf/9DTN7a5an+lPJBYZtMAAFAXhJGgJ6S8Z2TpgFWTKy05GhdGqBkBAKAeCCM+k+8ZMcYJconj38Z0glDACgBAfRBGTGnPiOT3jjgloSSMKAIAQH0QRvxUEaoBcWzhSr6FfSY2jBBHAACoB8JI0DPihjdKomcEAIDTgTBSSBU21P1hrFO4VeQ28jQKWAEAqAvCiN8zYos9I/6S8H7hKgWsAABMHcJIINwzEh2mSVnpj//V1fv3eTFHAwCAySCMlC0HL5nCafHDyBuOWl3ZZ/XRR8NhhDgCAEA9EEYCoTBSMpsmk8vfpkPDNZSMAABQH4QRv2fEhHtGomEkVSgnic6qIY0AAFAPiQ8j1r82jWyw1og/m8YPH+mYQlaiCAAA9ZH4MBJmCmMvpmSdkZQfRkIJxCOOAABQF4QRv2fEWPl1I8FsmkII8YdpwuuNEEUAAKgPwkiBlQ31jEQXPYsbpiGOAABQH4SRoGdEMoWAUbbOSCGERHpGyCIAANQFYUShq/aWFLCWzaaRghRCFgEAoD4IIz4zfgGrVAwoLHoGAEB9EEYKvHABa0kYCS925m+LuVwNAACoAWHEX+BMoZ6RsmGaYi9IcXovPSMAANQDYSQ0tbesgNWf2hvuGSncJ4oAAFAfhJFC/WpkBdaSqb2pmGEaakYAAKgPwkhwbZrwMI2RrA1OTjiMNGWli/d7SmUJIwAA1ANhpCA8YdfIRNYUSbvF+1c95ukv7vO0al/udDYPAIBpizASrhkJrTMSvg5NuGdk7mD+ds5xekYAAKgHwkiw6Fl4BVZVDCNxq7ECAIDapRvdgEYLMoUpFrD+9/9b+rflxbQRHqbx7xsWGgEAoC7oGSn0jHgqFrDOHDZ626+LYSTcMxJcNI+L0wAAUBeEkQITWmdExijlxYcR/zo1zOwFAKA+CCOhAlZ/mMbKKYYOlQzTBD0jp6t9AABMb4SRYNEzE+kZSccUrUpS2i0WuQIAgMmrKYxs375dS5cuVUtLi7q6urRnz56Kxz766KN617vepblz56q1tVUXXHCB/vZv/7bmBtefv+hZqGfEOJHekLhhGgpYAQCoj6pn0+zcuVMbNmzQ9u3b9a53vUtf+9rXtHr1aj399NM6++yzy46fOXOmbrrpJr3lLW/RzJkz9eijj+ozn/mMZs6cqT/5kz+py5uYnMIwjWxQwGplImEkPCSTZmovAAB1VXXPyNatW3XDDTdo7dq1WrZsmbZt26aOjg7t2LEj9vhLL71U11xzjS666CKdc845+uQnP6n3v//9Y/amNIKVosM0bvxxQc8IYQQAgLqoKoyMjo5q37596unpiWzv6enR3r17J/QafX192rt3r97znvdUPGZkZESDg4ORr6njF7AqWsBa6AE51TJXP7/wjzQ4O9/rU+wZIY0AAFAPVYWRI0eOyHVdtbe3R7a3t7fr0KFDYz53yZIlam5u1ooVK3TjjTdq7dq1FY/dsmWL2tragq+Ojo5qmlkbE98z8vMLP63DC1bosa7/Lqk4s8ahZgQAgLqoqYDVGBN5bK0t21Zqz549euyxx3TXXXdp27Zt+t73vlfx2E2bNunYsWPB14EDB2pp5oTYSAFroWbEhHpGZiyIHM9y8AAA1FdVBazz5s1TKpUq6wU5fPhwWW9JqaVLl0qSLr74Yr300ku69dZbdc0118Qe29zcrObm5mqaNgnhAlZ/mCY0tddGu0DS1IwAAFBXVfWMNDU1qaurS729vZHtvb29Wrly5YRfx1qrkZGRar711PHXGTEmdpimtDaEnhEAAOqr6qm9Gzdu1LXXXqsVK1aou7tbd999t/r7+7Vu3TpJ+SGWgwcP6t5775Uk3XnnnTr77LN1wQUXSMqvO3LHHXfo5ptvruPbmIzxVmCNpg5qRgAAqK+qw8iaNWt09OhR3XbbbRoYGNDy5cu1a9cudXZ2SpIGBgbU398fHO95njZt2qT9+/crnU7rTW96k26//XZ95jOfqd+7qIvitWmsMUr5nSQVhmlYDh4AgPqoOoxI0vr167V+/frYfffcc0/k8c033/xb1AsSx68ZMcUhGVMcvSodpmHRMwAA6otr0/giwzThmUHxqYMwAgBAfSQ+jNigZ0SRYRpf6TBNcfuUNw0AgERIfBgJhmmcUPCIDNMUw8ix2efo4OLfkZXkeKQRAADqoaaakWkl6ASJH6YxoWGaX55/jY7PWqI5g8/J2BdOYyMBAJi+6BmJHaYJnZZQAWs2PUOSlEu3MpsGAIA6IYwUWFNhmEZe6BincJuiZgQAgDohjIR6RoJr0yi+gNU6+VEtz6ToGQEAoE4SH0b8TGFNsRckOkxTDCOeSRX2pwrX1SORAAAwWYkPI/Kn8ZriAmeRqb2hAlYbhBFHjpW8CtN+AQDAxBFGwtemCepD4gtYvcIwjXVScrz8lX4BAMDkEEYKwsvBV1z0rDB84/nDNIQRAAAmjTASntpry3tGTEzgsH4BK1kEAIBJI4wUWCNpgsvB+2GEnhEAACYv8WHERgpY42bTxPSMFGpGXh1+Vf2D/aejmQAATFuJDyPxwzTh2TTlPSOecWQkrf3RWn34//mwXh1+deqbCQDANEUYKfAcSeMsBx9sMvmekRePv6icl9PRU0dPTyMBAJiGCCNBL4iJHaapVDNiQuuMeDG9JwAAYGIIIwXW2GBqrypctbd4bL6A1bVu/jErsQIAULPEhxG/gDV/PZqJFbB6jhOZTcNKrAAA1C7xYcRnKywHH+okCR2brxkJHjPFFwCAmhFGIrNp/FBRPC025hTZkqv2MkwDAEDtCCPBtWmk4jBNuGekvGvEL2D1MUwDAEDtEh9GbCFr2MhsmmIAsTHjNJ4T7RlhNg0AALVLfBjxe0Y8E7pQXvi0mPhhGsMwDQAAdUEYKbAmtNpqKIDY2GEaRybUGcIwDQAAtSOMFIKHlYJpvNFhmvJTlM3M0r4Vt6r7ud+XRBgBAGAyCCMF1oRqRiLDNOU9I4OzOzXcOl/nvHJx4XiGaQAAqFWiw0gumw3u54dpCqEiPEwTU8DqppolSY5N5Y+hZgQAgJolOoyEeTJSzGyauAJWL9UkSXKsU3guwzQAANQq0WHEc93gvo3Mphl7aq8vZdP516FmBACAmqUb3YBGcsNhRNHZNL847xo1jQ7G1oz4HI9hGgAAJivRYcRzc8F9a0wwm2akqU1H5r1FxrqaefzFis8PhmnoGQEAoGbJHqbxij0aXmg2jZfKSMovbmZjakZ8TmGYhtk0AADULtlhJNwzIqPCaiPyTKq43UmVPi3gyJGxhp4RAAAmIdlhxCuGEc+ouM6Ikw5trxxGpPz0XsIIAAC1S3YYiRSwOsVhmnDPyATCCMM0AADULtlhxCv2aHihRc/CPSPjhhEvxWwaAAAmIdFhxLrFMJKfTRPTMzJGzYgkdbzsMEwDAMAkJDqMRGpGpGDRM6+KmpHNOyW9dmwqmgcAQCIkPIyEe0acYNEz62RC28cOI0ZpOa8OTU0DAQBIgESHETcXqhlRcdGzsPHCiHVSsrncmMcAAIDKEh1GrC3OpvGMU7xqb/iYcWpGrEnJhmblAACA6iQ6jESGaVRcgbWq1zApWY8CVgAAapXsMOKWDtNUHyqsk5LoGQEAoGbJDiNeMUS4jokdphn3NUyaYRoAACYh0WFEXngF1tqGaaxJSQzTAABQs0SHkegwTaq2MOJQwAoAwGQkO4yEpvJ6RlJNwzQpWY8wAgBArRIdRqwbvmqvU/swTY4wAgBArRIdRly32BOSvzZNDT0jDj0jAABMRqLDiGdLClhrGKZh0TMAACYn0WEkWFfEerKqfZjGeNWHGAAAkJfoMGK9cAFrrcM0aYZpAACYhGSHkWBqr5Vkgqv2VvUaDNMAADApiQ4j/rVpjM1P7Z3IMI3xolfozS8Hz6JnAADUKtFhpHjVXivJmdAwTcobjTxmnREAACanpjCyfft2LV26VC0tLerq6tKePXsqHvvAAw/oyiuv1Pz58zVnzhx1d3frhz/8Yc0NricvqBmx8szEhmkcNxpGrEmzHDwAAJNQdRjZuXOnNmzYoM2bN6uvr0+rVq3S6tWr1d/fH3v8I488oiuvvFK7du3Svn379L73vU8f/OAH1dfXN+nGT5YNDctYa2Qm1DOSjTz2HIdFzwAAmISqw8jWrVt1ww03aO3atVq2bJm2bdumjo4O7dixI/b4bdu26Qtf+ILe/va369xzz9Vf/dVf6dxzz9X3v//9STd+svxr0+RDyMSm9qbckchjLpQHAMDkVBVGRkdHtW/fPvX09ES29/T0aO/evRN6Dc/zNDQ0pLPOOqviMSMjIxocHIx8TQXrhS+UZzTutWmsV17AyjANAACTUlUYOXLkiFzXVXt7e2R7e3u7Dh06NKHX+Ju/+RudOHFCf/iHf1jxmC1btqitrS346ujoqKaZExeqGbETmE3jeDk5Njok4zGbBgCASampgNUYE3lsrS3bFud73/uebr31Vu3cuVMLFiyoeNymTZt07Nix4OvAgQO1NHNcXqhHwyo1bs2Isa5MSRhhmAYAgMlJV3PwvHnzlEqlynpBDh8+XNZbUmrnzp264YYb9I//+I/63d/93TGPbW5uVnNzczVNq4mVV3Jv7FCRzp2SKZnG65mUHKb2AgBQs6p6RpqamtTV1aXe3t7I9t7eXq1cubLi8773ve/pU5/6lL773e/qAx/4QG0tnQK2cNVeY61kxp5Nc8EvvqMLf3GvnJKhHOukZFyuTQMAQK2q6hmRpI0bN+raa6/VihUr1N3drbvvvlv9/f1at26dpPwQy8GDB3XvvfdKygeR6667Tl/5yld02WWXBb0qra2tamtrq+NbqZ5VsUfDk6lcM2I9LT70H5KkA0suj+4yXJsGAIDJqDqMrFmzRkePHtVtt92mgYEBLV++XLt27VJnZ6ckaWBgILLmyNe+9jXlcjndeOONuvHGG4Pt119/ve65557Jv4NJsOECVjmqNJsm3GNSWjPiGYeaEQAAJqHqMCJJ69ev1/r162P3lQaM3bt31/ItTovwVXvtWD0joVqS0poR66RlmE0DAEDNEn1tmuJsmnzPSKUwEu4ZKZvaa5jaCwDAZCQ6jAQXxrNWnpEqDtOofJjGv2VqLwAAk5PoMOKvwJpfezWlfB6JCRahbX4I8ZeFt05KxmM2DQAAtUp2GAkyhJUtLNoWN7032jOSDyapXD6MePSMAAAwKckOI6Fi1GLnRlzPiFWucKb8Bc5S7nB+l5OmZgQAgElIdhixxam9MvlTEdszYj25hTPVeuqwJGnmyfx6KdSMAAAwOTVN7Z0ugqm9VvJzmYktYrVyU5Jy0hte3KMzX/2lsk2z9fL8S1lnBACASaJnJH+vGEFiClhNaJjGSJp56rAcL5c/3EnLEEYAAKhZssNIMJvGysovYI0LFjYYpvH5s2o8w7VpAACYjGSHkUh9SCGMxAzTGOvlh2ki21hnBACAeiCM5O8FPSOxwzQqDtP4/Fk1rDMCAMDkJDqMhBYakbVjDNNYq1yFnhHWGQEAYHISHUbiekZih2liakaCAlaTpmcEAIBJSHYYiUzt9YdpYoJFSc1IzgnVjDipoBAWAABUL9FhpFgfMvZsmvDUXknKpYphRJKMZ6aylQAATGuJDiN+z0jk2jMVhmm80JlynWIBa/51CCMAANQq2WEkFDysvwJrhav2eqZ41ZrSnpETmeVyswzVAABQi2SHkSA/WMlWrhnJ94yYoHekNIwcnv0hPfXoi1PbWAAApqlEh5HI1N7CrYm9am++Z8TPK64TlLsGnv/5kSlpIgAA0x1hJH9nzGEaI5sfpikkkNI1RyRp3pJZU9RIAACmt0SHkWLNSHgF1ripvYUw4g/TxJw1N8taIwAA1CLZYcQW1xkZa5jGyMqGhmn8npE5x34THJPLUcAKAEAtkh1GvGLPSHAq4gpYrSfPKQ7T+KuxvvWJO7Xkhd35bVm37HkAAGB8iQ4j0SVFxr42jY2pGUm7w2o99bIkMbUXAIAaJTqM2PAKrN7Y16YJF7C6qeJcGv8aNW6OmhEAAGqR6DDiD8kYadwC1kjNSOisOTYfRnL0jAAAUJNEh5Fi7hjn2jSKzqYJX8HX8bL5bTlqRgAAqEWiw0h0nRF/mGaM5eBj1hkJwgg9IwAA1CThYSR8d7zl4EMrsEbCCMM0AABMRqLDSHGdEauxZtMYW7ICa+wwDQWsAADUItFhRJGr9laeTSN5skb69SKjU03Swbkxs2lYZwQAgJqkG92ARgoXsPpjMHE9IyNpq5++yehnbzZqykornykGFmpGAACYnESHEXnlF8pTTBh58hxp37n5/SNNkmfKwwjLwQMAUJtED9PYyDBNXtwwjTW25HHxPoueAQAwOYkOI4pdZyQmjJRM9w1nk2LNCD0jAADUIuFhpLyANW6YprRnxImEkWzhaVaeSyABAKBaiQ4jsSuwxg3TlGwzMWFEYq0RAABqkegwEmZt/lTEzaYp7RmJG6aRJI+6EQAAqpbsMBJZDj7YWH5YSc1IeJjGyMp4+TVG6BkBAKB6iQ4jNlKsWrlnRGP0jEhcLA8AgMlIdBgJz6YZazl4b4yaESm01gg9IwAAVC3RYcTvGDGhAta4YRqZysM0UrFuZPTFl+rcQgAApr9EhxE/eFiFrk0TV8A6Xs+IzYeRl7729fo3EQCAaS7ZYaTQNWKslbVjLHpWWjNSst8fpskOHq9/GwEAmOYSHkYKNya06JnG7xkpH6YpFLBSvwoAQNUSHUaC69HYcZaDN5WXg5dCS8ITRgAAqFqiw0i4E8QGU3v9OhIvtC+aPn69KPoyfhjxmEwDAEDVkh1GZEtuJT+huKbYzVFaM/JUp6P/+QeO/vc/SUkKTe0ljAAAULV0oxvQSOFVV23Jomeuk1PazQR7S+07N3+8Z0IFrCwHDwBA1ZLdMxLKDqWzaTxTvOZMac1IWD6M5I/NkkUAAKhaosOIjVybJjqbxnVCwzRxC6H5Rzuhi+XZ1BS0EgCA6S3RYSRcClK66Jkb6hkpmz4TEh6mkUmXXO8GAACMJ9FhJL5mpDBM4+QieytxnWIY8ZyMlMtVPBYAAJRLdBgJK8aN8p6RidaMeE5aNpudohYCADA9JTuMhK7aW9YzYqqvGbEmQxgBAKBKCQ8j4ZARDSNueJhmgjUjLj0jAABUraYwsn37di1dulQtLS3q6urSnj17Kh47MDCgT3ziEzr//PPlOI42bNhQa1vrzoZ6RnwmbtGzcXtGijUjhBEAAKpTdRjZuXOnNmzYoM2bN6uvr0+rVq3S6tWr1d/fH3v8yMiI5s+fr82bN+uSSy6ZdIOnXFwB67g9I6GakdHRqW0fAADTTNVhZOvWrbrhhhu0du1aLVu2TNu2bVNHR4d27NgRe/w555yjr3zlK7ruuuvU1tY26QZPjVDPSMzUXhtzJV+f50iO9cNIRh5hBACAqlQVRkZHR7Vv3z719PREtvf09Gjv3r11a9TIyIgGBwcjX1MiZpimaTT/vU42DckrhBBrbOzVfKVozYjnpJUbHZ6atgIAME1VFUaOHDki13XV3t4e2d7e3q5Dhw7VrVFbtmxRW1tb8NXR0VG3146IyRfzjj6hMwa26786/t/QlF5b8USVrjOSHTk1JU0FAGC6qqmA1RgTeWytLds2GZs2bdKxY8eCrwMHDtTttcfjWE9Nw09pJHMyGJ6xprhYfCnPSOlcPoDk0q30jAAAUKWqrto7b948pVKpsl6Qw4cPl/WWTEZzc7Oam5vr9nqV2Jh7kf3GSlby5MmxUlwiMZIy2ROSpGxmlnIjhBEAAKpRVc9IU1OTurq61NvbG9ne29urlStX1rVhp0XoQnlhA3PzqSOYRWOsTIXAknKlTPa4JCmbmaksYQQAgKpU1TMiSRs3btS1116rFStWqLu7W3fffbf6+/u1bt06SfkhloMHD+ree+8NnvP4449Lko4fP66XX35Zjz/+uJqamnThhRfW513UqiRffPmTjt7xjNU/rfJ3F4ZpxqgZSXvFnhEZR6eOj0xNWwEAmKaqDiNr1qzR0aNHddttt2lgYEDLly/Xrl271NnZKSm/yFnpmiOXXnppcH/fvn367ne/q87OTj333HOTa/2k+eMu+VTy/73B6KkORzO8fAjxjF8z4lUOI67kWFep3Cm56VadOsGiZwAAVKPqMCJJ69ev1/r162P33XPPPWXbbIVpsb9t/GjiFJrrD9NYWVVa9yxTWI4kkz0uN92q4ZNctRcAgGok/No0/k3+jglu/e3jz6ZJF2b/NhWGakZOVl4gDQAAlEt0GLEl4SPoGfH3+8M0GnuYRioWsY4Mvz56gQAA+G2R6DBSWjNSttXE94ykQsNOmZIwMkr9KgAAVUl2GCnpxAh6SArbPRWn/jq2/Lgwf0bN6EiyTykAANVK9l/O0pqRwuPSYRrPeJEA4sSMxGSyQ5KkbDbZpxQAgGrxl1PlPR2lwzRSdJjGiVkAzS9gzeZqmqAEAEBiEUakoEuktJDV7zEprRmJH6bJ14zk3MyUNBEAgOkq0WGkdDH4spoRE1qBNdQZkop5Lb9mhDACAEB1Eh1GgoXMbIWekQqzaZyYRdyCnhGvqf4NBQBgGkt0GPGZknEXpxA9POMWbksKWGNeww8jrprluix8BgDARBFGFLP4WaHj4+cL9+ilOU/r0OxfR5aDjw8jJyWbDyED37pP3jBX7wUAYCKSPfXDRrtE/MDhb312/mM62fZTjaaNzGj5cZHnymrGyZd0cuYi7f/mA5o1d4bO+G+/PyXNBgBgOkl0z4iNuScpduaMCW0Nn7SHLs5vPzpbmn38BUnS8VlLlDs0UM+mAgAwbSU6jPhKC1fjwkj4RIXXGfnaVY7+j0+n9MBKR7OPH5AkDc3uUO7VV6eotQAATC+JDiOlwy2lNSPh+5GakdB9zzF6vt1oNC3NGsr3jAzNWqKTRw7Vv8EAAExDiQ4jtmQ5eF94SGas3pKwXEpBz8hw63z98vmn6tdQAACmsUSHkVLxwcNU3BaWS0mZ3Ek1D78iSRoZbpuaRgIAMM0kPIwUF36PbI0dpjGx+325wrKsfu+I57yhXo0EAGBaS3YYqVQzErMtLO6k5Qob5ww+J0kabe6cXNsAAEiIZIeRQGHRs2CdkdpqRiSpbXC/JOn4rHNY+AwAgAlIeBgxkZuSrYX7JnIrVegZSef3zx7ql6ynkZazNNj/ch3bCgDA9JTwMBIVxI1xpvbG1owUzmTaHdGsEy9Kkp75zxd0/FV6RwAAGEuyl4MPxE3tjb+Sb3F/lD9MI+XrRo7PWqKf/fiUfr53t66943K1zORqvgDw22DolWEdeSF/cVPP9XT4uUENvTKiTEtK7/zgGzVjToJ+Xx9/WTr0RP5++0XS7IUNaUayw8gEClgVBJNQQBljNo0knfHar/Ti4t+RJI3aJj35D4/qrR9ervSZZ8g0JehDDgBTwHM9HX91RJ6X/2U88qtf6cSP98o7MaSTP31MgydSGp7bqTM+/nGl584NnpfLenq5f0j7/9cRWS/mF7mk3KirK//oogm1Yzg3rJ2/3KkPvelDOrPlzMm/sdPtxT7pWx+Qsifyjz/6DeniP2hIU5IdRkqm9gb1Iba8gDXuWWHhMNJ+eJ8k6dUzl2lgUbf+62fSL3Z/X2e99rTmj/bJdVwpnZIyaamlSU5Li9KZJqVPDsvIlVqMbGtGmpGWndEkO6NZ2RlpHW3O6aXMiE5krGw6JZtJ5W+b0zKOI2OMHOPIyMgYI+OmZbyUHDkynpHjGaWyUvugozkjaUmOrJXcXEqum5bnpeXmUrKeI09pWZuSp4w815HrpZRzjVxPUv4VJZPKnzlr8gvIWSNrraxnlMs5MvKUsjl5WSvPNTLWVdrk5JisUiartMnJyJOVI8868uQoZUbVbI7Jc63MiRGlBk/KGRmW0ml5mbTkOLLGFG+NIzlG1nEkY2QzGXmZjGxTRl5TRplMVqlULv8zNqbwwzOSY+RZR9lcq6wtvI/CPmP8aygaGSd/m99f+HwYFb53/vspk5ZyOWU8V7PmzFR6ZqtMa4tMS7NMS7McIxlTCLO28Hkz+dvoMGDxl2N+t5WxVsY4OqO5Tc2ZtEzKyjO5/Ip9Xv4YWSPrebLDw7KnTsnmvPwbcBxZpeRZ5X92ruR50U98ceG//HuzNm6f/zgfyl1PymWt3JwN/jEYE9yJ3BojmVRaJpOSnJSM9WQ9L98Qz8p6ruS6srmc5LmFc158DeP/vEI/O39//rZwTOn+dFpOJiM5xZFo/0cQ/V+Ijfxfo/BjVTptlE7nX8va4s/NSpJngxUT/X3W3x86Nr+9cJzryWaz+S8vui9ylSwb/piEvoe/35NcV8rlbPCzjLyXmLvBg/i/vWMeZyu+ZrjB479O7JOt5A0P53/2hdfyTp7Mv8HIzz3/szUy8oyjwdwMvTIyS65NlbzgBfmbzrcXNz30qqT4S3PMfcMspZvyn48z22dozvxW/df39+tX//mSZnZKx1ODeuXUUT3zyi+UdbOSlU5mT+roqVfUPmOBzmw+S7965Vk93fpfevnky/r82z8f+32m0snRnFKOUcZx9PTAoE5lXaUco7edXRKMjv5a+vn9Um5EkpVeeko69HNpZDAfROYskWacKbWccdrfgy/hYaSE9X8rFfnBxEgy1sqauEGaaBgxkhYe3qe5rzytgUXdkqTBOUs1OGepntMHKn//OaH7rqRBT2Yw9Mut8CfDscX7/m8vY3My3rA8p0WOdSU5yjbNUZzjlVvw2yUjae64R5XLFr5O1Lc51RspfNVDw98Mpr2J/ternjIlj8+a8DMdLyvj5eSHFq/wnwRrJC81qIWHnpfjuRpudmSN5KaMBs9I6ei813TgzF/oxVn9xRdzJR2SLj3rY1ryyqXq+79eKuyYoQV6W+T7nhu6/w5dpNeWvaCT//ljff+RX1XxvsdWuip4nJxrdXhoRGnHaGZzSq+dzEqSmtOO3nbusLT/4fzfh7PeKL36nJQ7Ff9CCy6UPv1DqSX+78XpQhiRgnGXuJkzxaLWYiVJuOfEFw4jr82QzjgpZXKnNGNwl0Zb361c80/lmrcq5VbRlWec0P/YC80Y8wmzJeX/XVVkPRnrSfLy//OWJ8cbkeMNy3GH5Xgjks3J2KyMdfMhx44WvnKSPBlrJXmysoWeDT8ceYX/xXky9qRcx1E206RcalTZVE7WSUmmVVJr/ta0SEpLNiep8GXmSs4CyWblprLKply5qfyPyHiFUFg4EZHbwn3HSo7n3zqyqbmyZkb86ZUnJ3dUxjsZPcmhqqHiZ6F8crexfkjN/wK0RnI8I2NN0I7geFO8X9L/UexNULGHQir0vvjPMZI1abmpJnlOpvAz8IOoF9z3f67+fWNt/ufoZeXYURnrFn7uhRNmbb5F/m1wX8HnI3+O/e+l/Gt5WTk2W2hHyfsJ//uxklM4H5Ezb5T/4+FIbuEPhVf432+kgLzktYJzX2F7+HuayP8tytsWfBsT/tlK1qTkORm5qabIz6OsRyVyv1Jviw1+v3hGco2VDT4OY7yGf15N6H7+VfL/Nr1s4d9N2dsaU8mPYez9MceN9fsn5tfiuN97NC25TvG5IxkpmzKRf9vG//wVHlvvqDxvv3Ia0MBZ0slmaeAsowPzow34bz/2dM0jZd1H+q/zjB74aGmvSt6rSx/Q+9wWNedmqMlaOfI02/OUkScjK0dWzdbqlJP/jZWRp6+9/CstTB8Y+81PFf9tjCr61/zZ0P2Xn8nfdr5LWnhx/v6sBdLZ3dLwManjnQ0PIlLSw0iFf1mRmpCYIZuxFj2TpNbR4n3nA52a6QwqnVmuVMrIesc04kojOck4KaVTaaVSaaVTKbU0ZaTZC9XaOlNNKUcnR10dH87p+EhWJ4ZzOjHqSlZKOVJKRkZWTV5OTSMjypw6oczxU0rPzCjT3KJUU5Oa2jJymtL5r0xaJpVSqikj09KqlOPIMZLjGM1pySiTMjqVdTWc9ZRypLTjKJ0ywe2clozOmJFRxkiyrrK5rLIjp+TkhmVypwqhxZPxXBl5Mp4nIzf/x8q6+S54d0TKnpJyw1K6Vcq0SqmMIr/tIn8Y6rW9dF94e2il3Dp8j5GcJ9daeVbyPCt3eCQ/omKKfVueTL6n3xhlXWnUdTXqSjlb+B+RLewvxD3X8/Rq7jV51lPGNCltMvnXspLr5f+45ZxmZU2TXMeR9aw8m9NoNqeRbE7ZXE7GFH4OcgtjMflQmv9+rhybU9o7pVTulIx7XK57XFm5QRi2ZX8+jaR8/VPxn0j5XyM/UBnXSq4nm3LkpQpd74XPsC1GzMJ9P2GGwljw113BEFrpCIJNZeQ6GXkmIysjx83JyY8ryvNzX+Hnln9fXvlrGq9wnFEx1scNMXjhcZ/CUYX/1Iw1dBG+Hz7ORLeVxKOS18pINh2zrzjs41hXjjeqlM0GrxtuqX+2/W3FQO9vK7Sj8BatrHJyNWpzyipXPCLUaxttTcljaws/smIbi2/fPzYaxoI8F7df8yTN1Wzl/wvWLqu3lhyTW+Wqd8mQMqNZSVZzXxzRuX1DGj3vLP2R5mmhWmVU0tPdJJkL9+qNmq0zTKi+b4ygNaTLNTT+YXVnjNG8Wc0aGs7qxEhOnXNnqiVTSCetZ0rnr5aaZkqHnsz/vn3zFTG/s357JDqM2JKPTuX/A4f+Ry6VfnwlRXtG+i7M6LInshpaOEfX/28316m1v00cZVIZZZrjexySrLnRDQBQkTc8rLc6zrSaSNA23gFnnnMaWjF5iQ4jMR22ZXviK0TKhcPI0PveorPWfVJvfEvXZJoHAKgjp6Wl0U1ABYkOI77SHpFKASTYb6Pds1J+3DM4buEb1H7579WziQAATFvJDiM2clO2XSoWqxoVC+Jio4oxuucKR7NPWc3p5Iq9AABMVLLDSDCbIVo0Fj+bpnR/eZHarnfku0c2ZGbWvaUAAExXXJsmbIx5bZGi1rHn12pWZla9WgQAwLSX6DBSnE1T0jMSnjAfmdpbNhEu1swmekYAAJioRIeRUnGFq7HTfMdZ3ac13Vq/RgEAMM0lOoxUihQmPoJMeEGblhTTxwAAmKhEhxF/CCa4tlewo3ydkWg8GTuWNKWmz4I6AABMtWSHkYCt/DBynYy8uTPHXmezOcU6nAAATBRhRHHrr8YM0/gX3pLUlIq/yJKvc05n3doGAMB0l+h1RsquTRNcwyl+mKZ4obz4YZp//9i/a9gdVlvzuFcLAAAABYkOI4GybDH2NbP9MOJYKy90FcT5M+bXv20AAExziR6mKU7RLV2BNXJUcBvcKwSQRJ88AADqhL+nEXFxpHyOjRMzwwYAANQm2WGkZEpv8To05SuwhoOHX7463rLwAABgfIkOI7biSqrj9Yz4t6QRAAAmK9FhJDDGomdxU3udmKMAAEBtEh1GimHCRm7C156Juw6NX8qa6JMHAECdJPzv6SSHaRilAQBg0hIdRmzJ+IwZYzaNCe0tDtOQRgAAmKxEh5GKWSJmNk1YaSgBAAC14+9pyHgFqf7+FDUjAADUTaL/nvorqY65HHzM0E2iTxoAAHWW6L+r1p8948/ZtXEDMIX7lgJWAACmQqLDSKWr0FSqGfEzS3FqbzGNGFYdAQCgJgkPIxMXDhtOEEqKUiYlAABQvZrCyPbt27V06VK1tLSoq6tLe/bsGfP4hx9+WF1dXWppadEb3/hG3XXXXTU1tt4q9mZYJ/Z++XLwodcy9IwAAFCLqsPIzp07tWHDBm3evFl9fX1atWqVVq9erf7+/tjj9+/fr6uuukqrVq1SX1+fvvSlL+nP/uzPdP/990+68ZMVDLKU1LHa2JAS6hkp3A3XjNAzAgBAbaoOI1u3btUNN9ygtWvXatmyZdq2bZs6Ojq0Y8eO2OPvuusunX322dq2bZuWLVumtWvX6tOf/rTuuOOOSTd+8goLmgWX3y2fORMEExue2usfFaoZoWcEAICaVBVGRkdHtW/fPvX09ES29/T0aO/evbHP+Y//+I+y49///vfrscceUzabjX3OyMiIBgcHI19TyQ8cpQWsxlqFA4o/rBO+YN65Z54rSbqy88opbSMAANNVVWHkyJEjcl1X7e3tke3t7e06dOhQ7HMOHToUe3wul9ORI0din7Nlyxa1tbUFXx0dHdU0c8JMKIS0ZBxlvLQkKZs7QylrNcuz8txWSZLjNanFzR+/aP6FkqRZnqe7r7xb/6P7f2jzOzdPSRsBAJju0rU8qXRIwlo75jBF3PFx232bNm3Sxo0bg8eDg4NTEkiaFr4mHd2tM5fP091XrdBrR76sqwd/qOyb1+njIw+qKTNHr5x7ma4+8W2l3/wHmmkOKjv8hK56718pt/tLOu8N3ZrXOk8fO+9jdW8bAABJUVUYmTdvnlKpVFkvyOHDh8t6P3wLFy6MPT6dTmvu3Lmxz2lublZzc3M1TavJJ//nX0Y3nHeVpKsKD5aFdqwI3f+EJOnDl98+hS0DACA5qhqmaWpqUldXl3p7eyPbe3t7tXLlytjndHd3lx3/ox/9SCtWrFAmk6myuQAAYLqpejbNxo0b9fWvf13f/OY39cwzz+izn/2s+vv7tW7dOkn5IZbrrrsuOH7dunV6/vnntXHjRj3zzDP65je/qW984xv6/Oc/X793AQAAXreqrhlZs2aNjh49qttuu00DAwNavny5du3apc7OTknSwMBAZM2RpUuXateuXfrsZz+rO++8U4sXL9bf/d3f6aMf/Wj93gUAAHjdMtavJv0tNjg4qLa2Nh07dkxz5sxpdHMAAMAETPTvN9emAQAADUUYAQAADUUYAQAADUUYAQAADUUYAQAADUUYAQAADUUYAQAADUUYAQAADUUYAQAADVX1cvCN4C8SOzg42OCWAACAifL/bo+32PvrIowMDQ1Jkjo6OhrcEgAAUK2hoSG1tbVV3P+6uDaN53l68cUXNXv2bBlj6va6g4OD6ujo0IEDBxJ9zRvOA+fAx3nI4zxwDnych8mdA2uthoaGtHjxYjlO5cqQ10XPiOM4WrJkyZS9/pw5cxL7IQvjPHAOfJyHPM4D58DHeaj9HIzVI+KjgBUAADQUYQQAADRUosNIc3OzbrnlFjU3Nze6KQ3FeeAc+DgPeZwHzoGP83B6zsHrooAVAABMX4nuGQEAAI1HGAEAAA1FGAEAAA1FGAEAAA2V6DCyfft2LV26VC0tLerq6tKePXsa3aQpc+utt8oYE/lauHBhsN9aq1tvvVWLFy9Wa2ur3vve9+qpp55qYIvr45FHHtEHP/hBLV68WMYY/dM//VNk/0Te98jIiG6++WbNmzdPM2fO1Ic+9CG98MILp/FdTM545+BTn/pU2Wfjsssuixzzej8HW7Zs0dvf/nbNnj1bCxYs0O///u/rl7/8ZeSYJHwWJnIepvvnYceOHXrLW94SLODV3d2tf/mXfwn2J+FzII1/Hk735yCxYWTnzp3asGGDNm/erL6+Pq1atUqrV69Wf39/o5s2ZS666CINDAwEX08++WSw76//+q+1detWffWrX9VPf/pTLVy4UFdeeWVwXaDXqxMnTuiSSy7RV7/61dj9E3nfGzZs0IMPPqj77rtPjz76qI4fP66rr75aruuerrcxKeOdA0n6vd/7vchnY9euXZH9r/dz8PDDD+vGG2/UT37yE/X29iqXy6mnp0cnTpwIjknCZ2Ei50Ga3p+HJUuW6Pbbb9djjz2mxx57TJdffrk+/OEPB4EjCZ8DafzzIJ3mz4FNqHe84x123bp1kW0XXHCB/eIXv9igFk2tW265xV5yySWx+zzPswsXLrS33357sG14eNi2tbXZu+666zS1cOpJsg8++GDweCLv+7XXXrOZTMbed999wTEHDx60juPYf/3Xfz1tba+X0nNgrbXXX3+9/fCHP1zxOdPtHFhr7eHDh60k+/DDD1trk/lZsLb8PFibzM/DmWeeab/+9a8n9nPg88+Dtaf/c5DInpHR0VHt27dPPT09ke09PT3au3dvg1o19Z599lktXrxYS5cu1cc//nH95je/kSTt379fhw4dipyP5uZmvec975nW52Mi73vfvn3KZrORYxYvXqzly5dPq3Oze/duLViwQOedd57++I//WIcPHw72TcdzcOzYMUnSWWedJSm5n4XS8+BLyufBdV3dd999OnHihLq7uxP7OSg9D77T+Tl4XVwor96OHDki13XV3t4e2d7e3q5Dhw41qFVT653vfKfuvfdenXfeeXrppZf0l3/5l1q5cqWeeuqp4D3HnY/nn3++Ec09LSbyvg8dOqSmpiadeeaZZcdMl8/K6tWr9bGPfUydnZ3av3+//uIv/kKXX3659u3bp+bm5ml3Dqy12rhxo37nd35Hy5cvl5TMz0LceZCS8Xl48skn1d3dreHhYc2aNUsPPvigLrzwwuCPaFI+B5XOg3T6PweJDCM+Y0zksbW2bNt0sXr16uD+xRdfrO7ubr3pTW/St7/97aAoKUnnI6yW9z2dzs2aNWuC+8uXL9eKFSvU2dmpH/zgB/rIRz5S8Xmv13Nw00036YknntCjjz5ati9Jn4VK5yEJn4fzzz9fjz/+uF577TXdf//9uv766/Xwww8H+5PyOah0Hi688MLT/jlI5DDNvHnzlEqlytLb4cOHyxLxdDVz5kxdfPHFevbZZ4NZNUk7HxN53wsXLtTo6KheffXVisdMN4sWLVJnZ6eeffZZSdPrHNx8883653/+Zz300ENasmRJsD1pn4VK5yHOdPw8NDU16c1vfrNWrFihLVu26JJLLtFXvvKVxH0OKp2HOFP9OUhkGGlqalJXV5d6e3sj23t7e7Vy5coGter0GhkZ0TPPPKNFixZp6dKlWrhwYeR8jI6O6uGHH57W52Mi77urq0uZTCZyzMDAgH7+859P23Nz9OhRHThwQIsWLZI0Pc6BtVY33XSTHnjgAf37v/+7li5dGtmflM/CeOchznT8PJSy1mpkZCQxn4NK/PMQZ8o/B1WXvE4T9913n81kMvYb3/iGffrpp+2GDRvszJkz7XPPPdfopk2Jz33uc3b37t32N7/5jf3JT35ir776ajt79uzg/d5+++22ra3NPvDAA/bJJ5+011xzjV20aJEdHBxscMsnZ2hoyPb19dm+vj4ryW7dutX29fXZ559/3lo7sfe9bt06u2TJEvtv//Zv9mc/+5m9/PLL7SWXXGJzuVyj3lZVxjoHQ0ND9nOf+5zdu3ev3b9/v33ooYdsd3e3fcMb3jCtzsGf/umf2ra2Nrt79247MDAQfJ08eTI4JgmfhfHOQxI+D5s2bbKPPPKI3b9/v33iiSfsl770Jes4jv3Rj35krU3G58Dasc9DIz4HiQ0j1lp755132s7OTtvU1GTf9ra3Raa3TTdr1qyxixYtsplMxi5evNh+5CMfsU899VSw3/M8e8stt9iFCxfa5uZm++53v9s++eSTDWxxfTz00ENWUtnX9ddfb62d2Ps+deqUvemmm+xZZ51lW1tb7dVXX237+/sb8G5qM9Y5OHnypO3p6bHz58+3mUzGnn322fb6668ve3+v93MQ9/4l2W9961vBMUn4LIx3HpLwefj0pz8d/N6fP3++veKKK4IgYm0yPgfWjn0eGvE5MNZaW31/CgAAQH0ksmYEAAD89iCMAACAhiKMAACAhiKMAACAhiKMAACAhiKMAACAhiKMAACAhiKMAACAhiKMAACAhiKMAACAhiKMAACAhiKMAACAhvr/AWekDt6ai5H5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "battery_model = Model(df_battery, battery_data, \"This is the model for the battery dataset\")\n",
    "features_battery = df_battery.drop(['ID', 'label'], axis=1)\n",
    "\n",
    "def condition_number(features):\n",
    "    A = features.to_numpy()\n",
    "    U, S, V = np.linalg.svd(A, full_matrices=False)\n",
    "    condition_num = np.max(S) / np.min(S[np.nonzero(S)])\n",
    "    return condition_num\n",
    "\n",
    "# normalize data\n",
    "df_norm = battery_model.normalize(True, False)\n",
    "features_battery_norm = df_norm.drop(['ID', 'label'], axis=1)\n",
    "battery_model_norm = Model(df_norm, df_norm.to_numpy())\n",
    "\n",
    "# standardize data\n",
    "df_stand = battery_model.normalize(False, True)\n",
    "features_battery_stand = df_stand.drop(['ID', 'label'], axis=1)\n",
    "battery_model_stand = Model(df_stand, df_stand.to_numpy())\n",
    "\n",
    "#print(\"Condition number of original dataset : \", condition_number(features_battery))\n",
    "print(\"Condition number of normalized dataset : \", condition_number(features_battery_norm))\n",
    "print(\"Condition number of standardized dataset : \", condition_number(features_battery_stand))\n",
    "print(\"---------------------------------------------------------\")\n",
    "#print(\"Error after training original dataset : \", battery_model.crossValidation(10))\n",
    "print(\"Error after training normalized dataset : \", battery_model_norm.crossValidation(10), battery_model_norm.avg_weigth)\n",
    "battery_model_norm.hyperparameterAnalysis(10)\n",
    "print(\"Error after training standardized dataset : \", battery_model_stand.crossValidation(10),battery_model_stand.avg_weigth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CKD Model 4: Quadratic model using all features available, where highest weighted features have a quadratic term\n",
    "\n",
    "# normalize data\n",
    "ckd_model = Model(train_df_CKD, train_CKD_data, \"CKD Model 1\")\n",
    "df_ckd_norm = ckd_model.normalize(True, False)\n",
    "ckd_data_norm = df_ckd_norm.to_numpy()\n",
    "ckd_model_norm = Model(df_ckd_norm, ckd_data_norm)\n",
    "\n",
    "# get weights of linear model using all training data\n",
    "train_data = ckd_data_norm[:,1:] # removing first column (ID)\n",
    "weights = np.array(ckd_model_norm.fit(train_data))\n",
    "print(\"Weights of linear model: \", weights)\n",
    "\n",
    "num_quadratic_features = 2\n",
    "top_weighted_features = np.argsort(np.abs(weights[:-1]))[-num_quadratic_features:] # taking top num_quadratic_features in magnitude of weights, excluding w_0 weight\n",
    "print(f'The {num_quadratic_features} features with the highest magnitudes weights are ', top_weighted_features + np.ones(np.shape(top_weighted_features)))\n",
    "\n",
    "# create new dataset\n",
    "df_ckd_quadratic = train_df_CKD.copy()\n",
    "data_ckd_quadratic = train_CKD_data.copy()\n",
    "\n",
    "for i in top_weighted_features:\n",
    "    df_ckd_quadratic[f'feature_{i}_squared'] = df_ckd_quadratic.iloc[:,i]**2 # adding a new quadratic feature to dataset\n",
    "\n",
    "# normalize new quadratic dataset\n",
    "ckd_model_quad = Model(df_ckd_quadratic, data_ckd_quadratic)\n",
    "df_ckd_quad_norm = ckd_model_quad.normalize(True, False)\n",
    "ckd_data_quad_norm = df_ckd_quad_norm.to_numpy()\n",
    "ckd_model_quad_norm = Model(df_ckd_quad_norm, ckd_data_quad_norm, \"CKD Model 4\")\n",
    "\n",
    "print(f\"Error for model with {num_quadratic_features} quadratic features: \", ckd_model_quad_norm.crossValidation(10))\n",
    "ckd_model_quad_norm.hyperparameterAnalysis(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of linear model:  [ 5.75770595  5.32042541 -0.36597877  0.1298155  -0.48009116 -0.17909957\n",
      " -0.88789417 -0.55023435 -0.1710874  -0.13552084 -0.0882606  -0.23785493\n",
      "  0.02596821 -0.52288818 -0.53135034 -0.54850226 -0.11986168 -0.46641928\n",
      " -0.0450794  -0.20978599 -0.02431803  0.07276487 -0.04179155  0.0316412\n",
      "  0.01128354 -0.45876124  0.02079946 -0.64431559 -0.45405818 -0.38985487\n",
      " -0.26232643 -0.24765017 -1.68339528]\n",
      "The 1 features with the highest magnitudes weights are  [1.]\n",
      "Error for model with 1 quadratic features:  (0.08773794485863369, 0.06153846153846151)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'i' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10768\\923002602.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Error for model with {num_quadratic_features} quadratic features: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbattery_model_quad_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrossValidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mbattery_model_quad_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameterAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10768\\1094041282.py\u001b[0m in \u001b[0;36mhyperparameterAnalysis\u001b[1;34m(self, folds)\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"plot {i}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrossValidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddPlot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"alpha = {round(a,3)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'i' referenced before assignment"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Battery Model 4: Quadratic model using all features available, where highest weighted features have a quadratic term\n",
    "\n",
    "# normalize data\n",
    "battery_model = Model(train_df_battery, train_battery_data, \"Battery Model 1\")\n",
    "df_battery_norm = battery_model.normalize(True, False)\n",
    "battery_data_norm = df_battery_norm.to_numpy()\n",
    "battery_model_norm = Model(df_battery_norm, battery_data_norm)\n",
    "\n",
    "# get weights of linear model using all training data\n",
    "train_data = battery_data_norm[:,1:] # removing first column (ID)\n",
    "weights = np.array(battery_model_norm.fit(train_data))\n",
    "print(\"Weights of linear model: \", weights)\n",
    "\n",
    "num_quadratic_features = 1\n",
    "top_weighted_features = np.argsort(np.abs(weights[:-1]))[-num_quadratic_features:] # taking top num_quadratic_features in magnitude of weights, excluding w_0 weight\n",
    "print(f'The {num_quadratic_features} features with the highest magnitudes weights are ', top_weighted_features + np.ones(np.shape(top_weighted_features)))\n",
    "\n",
    "# create new dataset\n",
    "df_battery_quadratic = train_df_battery.copy()\n",
    "data_battery_quadratic = train_battery_data.copy()\n",
    "\n",
    "for i in top_weighted_features:\n",
    "    df_battery_quadratic[f'feature_{i}_squared'] = df_battery_quadratic.iloc[:,i]**2 # adding a new quadratic feature to dataset\n",
    "\n",
    "# normalize new quadratic dataset\n",
    "battery_model_quad = Model(df_battery_quadratic, data_battery_quadratic)\n",
    "df_battery_quad_norm = battery_model_quad.normalize(True, False)\n",
    "battery_data_quad_norm = df_battery_quad_norm.to_numpy()\n",
    "battery_model_quad_norm = Model(df_battery_quad_norm, battery_data_quad_norm, \"Battery Model 4\")\n",
    "\n",
    "print(f\"Error for model with {num_quadratic_features} quadratic features: \", battery_model_quad_norm.crossValidation(10))\n",
    "battery_model_quad_norm.hyperparameterAnalysis(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
