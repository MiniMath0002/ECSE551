{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "# Group 13\n",
    "Mathieu Mailhot - Isabel Lougheed - Frank-Lucas Pantazis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- CKD: 28 numerical features, 1 target binary classification variable (\"Normal\" / \"CKD\")\\n- Battery: 32 real-valued features, 2 classes (\"Normal\" / \"Defective\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- CKD: 28 numerical features, 1 target binary classification variable (\"Normal\" / \"CKD\")\n",
    "- Battery: 32 real-valued features, 2 classes (\"Normal\" / \"Defective\")\n",
    "\"\"\"\n",
    "\n",
    "# load data sets\n",
    "\n",
    "# Calculate cross entropy or/ Information Gain for all the data without the threshold\n",
    "\n",
    "# statistical analysis on the datasets\n",
    "\n",
    "# - normalize\n",
    "\n",
    "# models: all features, selective features based on statistical analysis (dropping features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathieu Mailhot\\AppData\\Local\\Temp\\ipykernel_23220\\3014589073.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_CKD[\"label\"] = df_CKD[\"label\"].replace({\"CKD\": 1, \"Normal\": 0})\n",
      "C:\\Users\\Mathieu Mailhot\\AppData\\Local\\Temp\\ipykernel_23220\\3014589073.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_battery[\"label\"] = df_battery[\"label\"].replace({\"Defective\": 1, \"Normal\": 0})\n"
     ]
    }
   ],
   "source": [
    "# load data sets\n",
    "df_CKD = pd.read_csv(\"CKD.csv\")\n",
    "df_battery = pd.read_csv(\"Battery_Dataset.csv\")\n",
    "\n",
    "# Convert \"CKD\" to 1 and \"Normal\" to 0\n",
    "df_CKD[\"label\"] = df_CKD[\"label\"].replace({\"CKD\": 1, \"Normal\": 0})\n",
    "# Convert \"Defective\" to 1 and \"Normal\" to 0\n",
    "df_battery[\"label\"] = df_battery[\"label\"].replace({\"Defective\": 1, \"Normal\": 0})\n",
    "\n",
    "# Convert to a numpy array\n",
    "CKD_data = df_CKD.to_numpy()\n",
    "battery_data = df_battery.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Analysis Block\n",
    "\n",
    "# Class for the analysis\n",
    "class Stat_analysis:\n",
    "    def __init__(self, data, name, save_folder):\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        self.save_folder = save_folder\n",
    "        self.feature_distribution()\n",
    "        self.class_distrubution()\n",
    "\n",
    "    # Function to create a distribution for each feature\n",
    "    def feature_distribution(self):\n",
    "        for i in range(self.data.shape[1] - 2): # remove 1 and last column as we do not need them for the distribution of the features\n",
    "            feature_num = i + 1\n",
    "\n",
    "            plt.hist(self.data[:,feature_num], bins=20, edgecolor=\"black\")\n",
    "            plt.xlabel(\"Value\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.title(f\"{self.name} Distribution of Feature {feature_num}\")\n",
    "\n",
    "            filename = os.path.join(self.save_folder, f\"{self.name}_feature{feature_num}_distribution.png\")\n",
    "            plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "    \n",
    "    # Function to create a distribution for the class\n",
    "    def class_distrubution(self):\n",
    "        my_bins = [-0.5, 0.5, 1.5]\n",
    "        class_0 = \"Normal\"\n",
    "        if self.name == \"CKD\":\n",
    "            class_1 = \"CKD\"\n",
    "        else:\n",
    "            class_1 = \"Defective\"\n",
    "\n",
    "        plt.hist(self.data[:,self.data.shape[1] - 1], bins=my_bins, edgecolor=\"black\", align=\"mid\", rwidth=0.6)\n",
    "        plt.xticks([0, 1], [class_0, class_1])\n",
    "        plt.xlabel(\"Category\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(f\"{self.name} Distribution of Class\")\n",
    "\n",
    "        filename = os.path.join(self.save_folder, f\"{self.name}_class_distribution.png\")\n",
    "        plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "# Perform the stastical analysis\n",
    "CKD_stat = Stat_analysis(CKD_data, \"CKD\", \"CKD_distribution\")\n",
    "battery_stat = Stat_analysis(battery_data, \"Battery\", \"Battery_distribution\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,  data, description:str = None):\n",
    "        self.data = data\n",
    "        self.description = description\n",
    "        \n",
    "        self.accuracy_arr = 0\n",
    "        self.avg_accuracy = 0\n",
    "\n",
    "        self.weigth_arr = 0\n",
    "        self.avg_weigth = 0\n",
    "    \n",
    "    def normalize(self, normalize_by_max:bool, standardize:bool): \n",
    "        # Normalize the dataset\n",
    "        # I think you should only normalize by max OR standardize, and I think standardizing would produce better results\n",
    "\n",
    "        # Separate features and target\n",
    "        df = self.data # make sure data is a data frame\n",
    "        features = df.drop(['ID', 'label'], axis=1)\n",
    "        target = df['label']\n",
    "\n",
    "        df_norm = df # if normalize_by_max = false and standardize = false, will return original df\n",
    "\n",
    "        if normalize_by_max:\n",
    "            # normalizing by extremas, scales to [0,1]\n",
    "            # ensures data is well-conditioned\n",
    "            features_normalized = (features - features.min())/(features.max() - features.min())\n",
    "            df_norm = pd.concat([df[['ID']], features_normalized, df[['label']]], axis=1)\n",
    "\n",
    "        if standardize:\n",
    "            # z score normalization, good for gaussian distributions\n",
    "            # forces std 1 and mean 0\n",
    "            features_standardized = (features - features.mean())/features.std()\n",
    "            df_norm = pd.concat([df[['ID']], features_standardized, df[['label']]], axis=1)\n",
    "\n",
    "        return df_norm\n",
    "    \n",
    "    def crossValidation(folds:int): \n",
    "        # Split dataset into folds\n",
    "        # Train\n",
    "        # alternate validation set and store values\n",
    "        pass\n",
    "\n",
    "    def fit():\n",
    "        # Trains using gradient descent: Lecture 5 slide 55-58\n",
    "        pass\n",
    "\n",
    "    def predict():\n",
    "        # Predicts output: function at bottom Lecture 5 slide 44\n",
    "        pass\n",
    "\n",
    "    def Accu_eval():\n",
    "        # Validation\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number of original dataset :  3132.845804007023\n",
      "Condition number of normalized dataset :  17.632795820381176\n",
      "Condition number of standardized dataset :  1.6891992219130858\n"
     ]
    }
   ],
   "source": [
    "# DELETE AFTER\n",
    "# testing normalize\n",
    "\n",
    "df = df_CKD\n",
    "\n",
    "ckd_model = Model(df, \"This is the model for the CKD dataset\")\n",
    "features_ckd = df.drop(['ID', 'label'], axis=1)\n",
    "\n",
    "def condition_number(features):\n",
    "    A = features.to_numpy()\n",
    "    U, S, V = np.linalg.svd(A, full_matrices=False)\n",
    "    condition_num = np.max(S) / np.min(S[np.nonzero(S)])\n",
    "    return condition_num\n",
    "\n",
    "# normalize data\n",
    "df_norm = ckd_model.normalize(True, False)\n",
    "features_ckd_norm = df_norm.drop(['ID', 'label'], axis=1)\n",
    "\n",
    "# standardize data\n",
    "df_stand = ckd_model.normalize(False, True)\n",
    "features_ckd_stand = df_stand.drop(['ID', 'label'], axis=1)\n",
    "\n",
    "print(\"Condition number of original dataset : \", condition_number(features_ckd))\n",
    "print(\"Condition number of normalized dataset : \", condition_number(features_ckd_norm))\n",
    "print(\"Condition number of standardized dataset : \", condition_number(features_ckd_stand))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
