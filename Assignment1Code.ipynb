{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "# Group 13\n",
    "Mathieu Mailhot - Isabel Lougheed - Frank-Lucas Pantazis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- CKD: 28 numerical features, 1 target binary classification variable (\"Normal\" / \"CKD\")\\n- Battery: 32 real-valued features, 2 classes (\"Normal\" / \"Defective\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- CKD: 28 numerical features, 1 target binary classification variable (\"Normal\" / \"CKD\")\n",
    "- Battery: 32 real-valued features, 2 classes (\"Normal\" / \"Defective\")\n",
    "\"\"\"\n",
    "\n",
    "# load data sets\n",
    "\n",
    "# Calculate cross entropy or/ Information Gain for all the data without the threshold\n",
    "\n",
    "# statistical analysis on the datasets\n",
    "\n",
    "# - normalize\n",
    "\n",
    "# models: all features, selective features based on statistical analysis (dropping features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000e+00 2.04500e-01 7.64600e-01 ... 8.81170e+01 9.47710e+01\n",
      "  1.00000e+00]\n",
      " [2.00000e+00 4.82200e-01 3.53300e-01 ... 5.77680e+01 1.07200e+02\n",
      "  1.00000e+00]\n",
      " [3.00000e+00 4.60200e-01 7.85100e-01 ... 1.05234e+02 9.16810e+01\n",
      "  1.00000e+00]\n",
      " ...\n",
      " [3.28000e+02 2.53200e-01 6.52300e-01 ... 8.63860e+01 9.92350e+01\n",
      "  1.00000e+00]\n",
      " [3.29000e+02 4.24900e-01 4.52800e-01 ... 1.20111e+02 9.83120e+01\n",
      "  1.00000e+00]\n",
      " [3.30000e+02 5.40200e-01 3.66400e-01 ... 1.01204e+02 9.84400e+01\n",
      "  1.00000e+00]]\n",
      "[[1.000000e+00 5.854000e-01 6.264000e-01 ... 9.907300e+01 1.053899e+02\n",
      "  1.000000e+00]\n",
      " [2.000000e+00 6.277000e-01 3.841000e-01 ... 9.150650e+01 9.100220e+01\n",
      "  0.000000e+00]\n",
      " [3.000000e+00 5.428000e-01 2.937000e-01 ... 9.400780e+01 1.046438e+02\n",
      "  0.000000e+00]\n",
      " ...\n",
      " [7.300000e+02 6.007000e-01 1.742000e-01 ... 1.117456e+02 9.444620e+01\n",
      "  0.000000e+00]\n",
      " [7.310000e+02 5.074000e-01 4.975000e-01 ... 1.080145e+02 6.329760e+01\n",
      "  1.000000e+00]\n",
      " [7.320000e+02 3.038000e-01 2.555000e-01 ... 1.227282e+02 7.608850e+01\n",
      "  0.000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\issyl\\AppData\\Local\\Temp\\ipykernel_7036\\3497661233.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_CKD[\"label\"] = df_CKD[\"label\"].replace({\"CKD\": 1, \"Normal\": 0})\n",
      "C:\\Users\\issyl\\AppData\\Local\\Temp\\ipykernel_7036\\3497661233.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_battery[\"label\"] = df_battery[\"label\"].replace({\"Defective\": 1, \"Normal\": 0})\n"
     ]
    }
   ],
   "source": [
    "# load data sets\n",
    "df_CKD = pd.read_csv(\"CKD.csv\")\n",
    "df_battery = pd.read_csv(\"Battery_Dataset.csv\")\n",
    "\n",
    "# Convert \"CKD\" to 1 and \"Normal\" to 0\n",
    "df_CKD[\"label\"] = df_CKD[\"label\"].replace({\"CKD\": 1, \"Normal\": 0})\n",
    "# Convert \"Defective\" to 1 and \"Normal\" to 0\n",
    "df_battery[\"label\"] = df_battery[\"label\"].replace({\"Defective\": 1, \"Normal\": 0})\n",
    "\n",
    "# Convert to a numpy array\n",
    "CKD_data = df_CKD.to_numpy()\n",
    "battery_data = df_battery.to_numpy()\n",
    "\n",
    "print(CKD_data)\n",
    "print(battery_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Analysis Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,  data, description:str = None):\n",
    "        self.data = data\n",
    "        self.description = description\n",
    "        \n",
    "        self.accuracy_arr = 0\n",
    "        self.avg_accuracy = 0\n",
    "\n",
    "        self.weigth_arr = 0\n",
    "        self.avg_weigth = 0\n",
    "    \n",
    "    def normalize(self, normalize_by_max:bool, standardize:bool): \n",
    "        # Normalize the dataset\n",
    "        # I think you should only normalize by max OR standardize, and I think standardizing would produce better results\n",
    "\n",
    "        # Separate features and target\n",
    "        df = self.data # make sure data is a data frame\n",
    "        features = df.drop(['ID', 'label'], axis=1)\n",
    "        target = df['label']\n",
    "\n",
    "        df_norm = df # if normalize_by_max = false and standardize = false, will return original df\n",
    "\n",
    "        if normalize_by_max:\n",
    "            # normalizing by extremas, scales to [0,1]\n",
    "            # ensures data is well-conditioned\n",
    "            features_normalized = (features - features.min())/(features.max() - features.min())\n",
    "            df_norm = pd.concat([df[['ID']], features_normalized, df[['label']]], axis=1)\n",
    "\n",
    "        if standardize:\n",
    "            # z score normalization, good for gaussian distributions\n",
    "            # forces std 1 and mean 0\n",
    "            features_standardized = (features - features.mean())/features.std()\n",
    "            df_norm = pd.concat([df[['ID']], features_standardized, df[['label']]], axis=1)\n",
    "\n",
    "        return df_norm\n",
    "    \n",
    "    def crossValidation(folds:int): \n",
    "        # Split dataset into folds\n",
    "        # Train\n",
    "        # alternate validation set and store values\n",
    "        pass\n",
    "\n",
    "    def fit():\n",
    "        # Trains using gradient descent: Lecture 5 slide 55-58\n",
    "        pass\n",
    "\n",
    "    def predict():\n",
    "        # Predicts output: function at bottom Lecture 5 slide 44\n",
    "        pass\n",
    "\n",
    "    def Accu_eval():\n",
    "        # Validation\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number of original dataset :  3132.845804007023\n",
      "Condition number of normalized dataset :  17.632795820381176\n",
      "Condition number of standardized dataset :  1.6891992219130858\n"
     ]
    }
   ],
   "source": [
    "# DELETE AFTER\n",
    "# testing normalize\n",
    "\n",
    "df = df_CKD\n",
    "\n",
    "ckd_model = Model(df, \"This is the model for the CKD dataset\")\n",
    "features_ckd = df.drop(['ID', 'label'], axis=1)\n",
    "\n",
    "def condition_number(features):\n",
    "    A = features.to_numpy()\n",
    "    U, S, V = np.linalg.svd(A, full_matrices=False)\n",
    "    condition_num = np.max(S) / np.min(S[np.nonzero(S)])\n",
    "    return condition_num\n",
    "\n",
    "# normalize data\n",
    "df_norm = ckd_model.normalize(True, False)\n",
    "features_ckd_norm = df_norm.drop(['ID', 'label'], axis=1)\n",
    "\n",
    "# standardize data\n",
    "df_stand = ckd_model.normalize(False, True)\n",
    "features_ckd_stand = df_stand.drop(['ID', 'label'], axis=1)\n",
    "\n",
    "print(\"Condition number of original dataset : \", condition_number(features_ckd))\n",
    "print(\"Condition number of normalized dataset : \", condition_number(features_ckd_norm))\n",
    "print(\"Condition number of standardized dataset : \", condition_number(features_ckd_stand))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
