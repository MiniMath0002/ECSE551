{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "# Group 13\n",
    "Mathieu Mailhot - Isabel Lougheed - Frank-Lucas Pantazis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "## Checkout link: https://www.analyticsvidhya.com/blog/2021/11/a-guide-to-building-an-end-to-end-multiclass-text-classification-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "folds = 5 # between 5 and 10\n",
    "\n",
    "# Loading Training data\n",
    "df_train = pd.read_csv('train.csv', encoding='utf-8', encoding_errors='ignore') # errors were not pertinent characters\n",
    "df_train[\"subreddit\"] = df_train[\"subreddit\"].map({\"Boston\": 0, \"Canberra\": 1,\"Geneva\":2,\"Ottawa\":3})\n",
    "\n",
    "y = df_train[\"subreddit\"]\n",
    "X = df_train.drop(\"subreddit\",axis=1)\n",
    "\n",
    "# Loading Test Data\n",
    "df_test = pd.read_csv('test.csv', encoding='utf-8', encoding_errors='ignore') # errors were not pertinent characters\n",
    "X_test = df_test[\"body\"] # Not what we should do with the ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different stop word libraries\n",
    "\n",
    "# Checkout: https://towardsdatascience.com/text-pre-processing-stop-words-removal-using-different-libraries-f20bac19929a/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram (size: 12557)\n",
      " ['00' '000' '0001' ... 'zucchini' 'zurich' 'zxwr7mvro1z3kabb'] \n",
      "\n",
      "Unigram & Bigram (size: 62167)\n",
      " ['00' '00 33' '00 avec' ... 'zurich tried' 'zxwr7mvro1z3kabb'\n",
      " 'zxwr7mvro1z3kabb year'] \n",
      "\n",
      "Bigram (size: 49610)\n",
      " ['00 33' '00 avec' '00 bit' ... 'zurich migrations' 'zurich tried'\n",
      " 'zxwr7mvro1z3kabb year']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Observations\n",
    "# - bigram -> worse performance\n",
    "# - sublinear_tf -> seems to improve accuracy\n",
    "# - decreasing max_features -> seems to decrease accuracy (feature reduction)\n",
    "\n",
    "# TODO\n",
    "# - Create custom stop word list since default one might not be suited for our case according to documentation: https://scikit-learn.org/stable/modules/feature_extraction.html#stop-words\n",
    "# - explore different ways to extract features from text data\n",
    "stop_words = {\"like\"}\n",
    "\n",
    "tfidf_uni = TfidfVectorizer(ngram_range=(1, 1), sublinear_tf=True, stop_words='english')\n",
    "tfidf_uni_bi = TfidfVectorizer(ngram_range=(1, 2),sublinear_tf=True, stop_words='english')\n",
    "tfidf_bi = TfidfVectorizer(ngram_range=(2, 2),  stop_words='english')\n",
    "\n",
    "X_uni = tfidf_uni.fit_transform(df_train[\"body\"]).toarray()\n",
    "X_uni_bi = tfidf_uni_bi.fit_transform(df_train[\"body\"]).toarray()\n",
    "X_bi = tfidf_bi.fit_transform(df_train[\"body\"]).toarray()\n",
    "\n",
    "print(\"Unigram\", \"(size:\",str(len(tfidf_uni.get_feature_names_out()))+\")\\n\",tfidf_uni.get_feature_names_out(),\"\\n\")\n",
    "print(\"Unigram & Bigram\", \"(size:\",str(len(tfidf_uni_bi.get_feature_names_out()))+\")\\n\",tfidf_uni_bi.get_feature_names_out(),\"\\n\")\n",
    "print(\"Bigram\", \"(size:\",str(len(tfidf_bi.get_feature_names_out()))+\")\\n\", tfidf_bi.get_feature_names_out())\n",
    "\n",
    "# To get a better idea of the extracted features\n",
    "with open(\"features.csv\", mode='w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Write a header (optional, if you want)\n",
    "    writer.writerow([\"Feature Name\"])\n",
    "    # Write the features from the array\n",
    "    for feature in tfidf_uni.get_feature_names_out():\n",
    "        writer.writerow([feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(stop_words='english')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m12\u001b[39m))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#{\"Boston\": 0, \"Canberra\": 1,\"Geneva\":2,\"Ottawa\":3}\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbarh\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBoston_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBoston\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m ax\u001b[38;5;241m.\u001b[39mbarh(y_pos \u001b[38;5;241m+\u001b[39m width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, Canberra_counts, width, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCanberra\u001b[39m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m ax\u001b[38;5;241m.\u001b[39mbarh(y_pos \u001b[38;5;241m-\u001b[39m width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, Geneva_counts, width, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeneva\u001b[39m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\frank\\Documents\\ECSE 551\\ECSE551\\sklearn-env\\lib\\site-packages\\matplotlib\\axes\\_axes.py:2760\u001b[0m, in \u001b[0;36mAxes.barh\u001b[1;34m(self, y, width, height, left, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2641\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m \u001b[38;5;124;03mMake a horizontal bar plot.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2757\u001b[0m \u001b[38;5;124;03m:doc:`/gallery/lines_bars_and_markers/horizontal_barchart_distribution`.\u001b[39;00m\n\u001b[0;32m   2758\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorizontal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 2760\u001b[0m patches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbar(x\u001b[38;5;241m=\u001b[39mleft, height\u001b[38;5;241m=\u001b[39mheight, width\u001b[38;5;241m=\u001b[39mwidth, bottom\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   2761\u001b[0m                    align\u001b[38;5;241m=\u001b[39malign, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2762\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m patches\n",
      "File \u001b[1;32mc:\\Users\\frank\\Documents\\ECSE 551\\ECSE551\\sklearn-env\\lib\\site-packages\\matplotlib\\__init__.py:1476\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1476\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[0;32m   1477\u001b[0m             ax,\n\u001b[0;32m   1478\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args),\n\u001b[0;32m   1479\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: sanitize_sequence(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[0;32m   1481\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1482\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1483\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\frank\\Documents\\ECSE 551\\ECSE551\\sklearn-env\\lib\\site-packages\\matplotlib\\axes\\_axes.py:2597\u001b[0m, in \u001b[0;36mAxes.bar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# horizontal\u001b[39;00m\n\u001b[0;32m   2596\u001b[0m         r\u001b[38;5;241m.\u001b[39msticky_edges\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mappend(l)\n\u001b[1;32m-> 2597\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2598\u001b[0m     patches\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[0;32m   2600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\frank\\Documents\\ECSE 551\\ECSE551\\sklearn-env\\lib\\site-packages\\matplotlib\\axes\\_base.py:2414\u001b[0m, in \u001b[0;36m_AxesBase.add_patch\u001b[1;34m(self, p)\u001b[0m\n\u001b[0;32m   2412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2413\u001b[0m     p\u001b[38;5;241m.\u001b[39mset_clip_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch)\n\u001b[1;32m-> 2414\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_patch_limits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[0;32m   2416\u001b[0m p\u001b[38;5;241m.\u001b[39m_remove_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children\u001b[38;5;241m.\u001b[39mremove\n",
      "File \u001b[1;32mc:\\Users\\frank\\Documents\\ECSE 551\\ECSE551\\sklearn-env\\lib\\site-packages\\matplotlib\\axes\\_base.py:2455\u001b[0m, in \u001b[0;36m_AxesBase._update_patch_limits\u001b[1;34m(self, patch)\u001b[0m\n\u001b[0;32m   2453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m updatey \u001b[38;5;129;01mand\u001b[39;00m patch_trf \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xaxis_transform():\n\u001b[0;32m   2454\u001b[0m         updatey \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 2455\u001b[0m trf_to_data \u001b[38;5;241m=\u001b[39m \u001b[43mpatch_trf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransData\u001b[49m\n\u001b[0;32m   2456\u001b[0m xys \u001b[38;5;241m=\u001b[39m trf_to_data\u001b[38;5;241m.\u001b[39mtransform(vertices)\n\u001b[0;32m   2457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_datalim(xys, updatex\u001b[38;5;241m=\u001b[39mupdatex, updatey\u001b[38;5;241m=\u001b[39mupdatey)\n",
      "File \u001b[1;32mc:\\Users\\frank\\Documents\\ECSE 551\\ECSE551\\sklearn-env\\lib\\site-packages\\matplotlib\\transforms.py:1460\u001b[0m, in \u001b[0;36mTransform.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Transform):\n\u001b[0;32m   1459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m-> 1460\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m remainder, sub_tree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_break_from_left_to_right():\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sub_tree \u001b[38;5;241m==\u001b[39m other:\n\u001b[0;32m   1462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m remainder\n",
      "File \u001b[1;32mc:\\Users\\frank\\Documents\\ECSE 551\\ECSE551\\sklearn-env\\lib\\site-packages\\matplotlib\\transforms.py:2402\u001b[0m, in \u001b[0;36mCompositeGenericTransform._iter_break_from_left_to_right\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_iter_break_from_left_to_right\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 2402\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m left, right \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_a\u001b[38;5;241m.\u001b[39m_iter_break_from_left_to_right():\n\u001b[0;32m   2403\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m left, right \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\n\u001b[0;32m   2404\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m left, right \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\u001b[38;5;241m.\u001b[39m_iter_break_from_left_to_right():\n",
      "File \u001b[1;32mc:\\Users\\frank\\Documents\\ECSE 551\\ECSE551\\sklearn-env\\lib\\site-packages\\matplotlib\\transforms.py:2404\u001b[0m, in \u001b[0;36mCompositeGenericTransform._iter_break_from_left_to_right\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m left, right \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_a\u001b[38;5;241m.\u001b[39m_iter_break_from_left_to_right():\n\u001b[0;32m   2403\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m left, right \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\n\u001b[1;32m-> 2404\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m left, right \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\u001b[38;5;241m.\u001b[39m_iter_break_from_left_to_right():\n\u001b[0;32m   2405\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_a \u001b[38;5;241m+\u001b[39m left, right\n",
      "File \u001b[1;32mc:\\Users\\frank\\Documents\\ECSE 551\\ECSE551\\sklearn-env\\lib\\site-packages\\matplotlib\\transforms.py:1375\u001b[0m, in \u001b[0;36mTransform._iter_break_from_left_to_right\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_iter_break_from_left_to_right\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;124;03m    Return an iterator breaking down this transform stack from left to\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;124;03m    right recursively. If self == ((A, N), A) then the result will be an\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;124;03m    ``flat_stack[:i], flat_stack[i:]`` where i=0..(n-1).\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1375\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mIdentityTransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\frank\\Documents\\ECSE 551\\ECSE551\\sklearn-env\\lib\\site-packages\\matplotlib\\transforms.py:1780\u001b[0m, in \u001b[0;36mAffineBase.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1780\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inverted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draft of Feature Visualizer\n",
    "# Maybe should put all of it in an excel and then display it?\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_disp = vectorizer.fit_transform(df_train[\"body\"])\n",
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "Boston_counts = X_disp[y == 0].sum(axis=0).A1 # Sum occurrences for class 'Boston'\n",
    "Canberra_counts = X_disp[y == 1].sum(axis=0).A1 # Sum occurrences for class 'Canberra'\n",
    "Geneva_counts = X_disp[y == 2].sum(axis=0).A1 # Sum occurrences for class 'Geneva'\n",
    "Ottawa_counts = X_disp[y == 3].sum(axis=0).A1 # Sum occurrences for class 'Ottawa'\n",
    "\n",
    "# Plot a grouped bar chart\n",
    "y_pos = np.arange(len(feature_names))*2 # Word indices\n",
    "width = 0.4  # Bar width\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "ax.barh(y_pos + 3*width/2, Boston_counts, width, label=\"Boston\", color='red')\n",
    "ax.barh(y_pos + width/2, Canberra_counts, width, label=\"Canberra\", color='orange')\n",
    "ax.barh(y_pos - width/2, Geneva_counts, width, label=\"Geneva\", color='blue')\n",
    "ax.barh(y_pos - 3*width/2, Ottawa_counts, width, label=\"Ottawa\", color='green')\n",
    "# Formatting\n",
    "ax.set_yticks(y_pos, labels=feature_names)\n",
    "\n",
    "ax.set_xlabel(\"Word Count\")\n",
    "ax.set_title(\"Feature Appearance in Each Class\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Helper Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# This function does all the tunning for each model\n",
    "def hyperparamaterTunning(X, param, folds, model):\n",
    "    \n",
    "    model_gridSearch = GridSearchCV(model, param_grid=param,cv=folds, verbose=True) # According to doc the data will be split the same way accross all calls\n",
    "\n",
    "    model_best_clf = model_gridSearch.fit(X,y)\n",
    "\n",
    "    cv_results = model_gridSearch.cv_results_\n",
    "\n",
    "    print(f\"Best Parameters: {model_best_clf.best_params_}\")\n",
    "    try:\n",
    "\n",
    "        best_index = model_gridSearch.best_index_\n",
    "\n",
    "        scores = model_gridSearch.cv_results_[f\"split{best_index}_test_score\"]\n",
    "\n",
    "        print()\n",
    "    except:\n",
    "        pass\n",
    "   \n",
    "\n",
    "    print(f\"Cross-validation Accuracies: {scores}\")\n",
    "\n",
    "    print(f\"Mean Accuracy: {model_best_clf.best_score_:.4f}\")\n",
    "\n",
    "    return model_best_clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Naive Bayes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class naiveBayes:\n",
    "    def __init__(self, x_all, y_all):\n",
    "        self.x_all = x_all\n",
    "        self.y_all = y_all\n",
    "        self.features_probability = dict()\n",
    "\n",
    "        self.folds_features_probability = 0 # array of dict\n",
    "        self.folds_accuracy = 0\n",
    "        self.avg_accuracy = 0\n",
    "\n",
    "    \n",
    "    def calc_probability(self): # Train/Fit # Mathieu\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x_i): # Issy\n",
    "        pass # return y (0,1,2,3)\n",
    "\n",
    "    def accu_eval(self, x, y): # Issy\n",
    "        pass\n",
    "\n",
    "    def crossValidation(self, k): # Issy (PS: I think we are allowed to use the method from sklearn)\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "\n",
      "Best Parameters: {'alpha': 5.0}\n",
      "Cross-validation Accuracies: [0.69642857 0.73214286 0.75357143 0.73214286 0.72857143 0.725     ]\n",
      "Mean Accuracy: 0.7079\n"
     ]
    }
   ],
   "source": [
    "# Compare with Naive Bayes model from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "param_grid_NB_1 = {'alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "\n",
    "NB = hyperparamaterTunning(X_uni, param,folds, MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression Models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "\n",
      "Best Parameters: {'l1_ratio': np.float64(0.0), 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "Cross-validation Accuracies: [0.70714286 0.65       0.66428571 0.62142857 0.575      0.53571429]\n",
      "Mean Accuracy: 0.7050\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid_logModel_1 = [\n",
    "    {\"penalty\":[\"elasticnet\"],\n",
    "     \"l1_ratio\": np.arange(0, 1.2, 0.2), # 0 is only l2 penalty, 1 is only l1 penalty\n",
    "     \"solver\":[\"saga\"],\n",
    "     \"max_iter\": [1000]\n",
    "     }]\n",
    "\n",
    "logModel_tunned_1 = hyperparamaterTunning(X_uni, param_grid_logModel_1, folds, LogisticRegression(fit_intercept=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Best Parameters: {'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001}\n",
      "Cross-validation Accuracies: [0.70714286 0.70714286 0.70714286 0.70714286 0.70714286 0.70714286\n",
      " 0.70714286 0.70714286 0.70714286 0.70714286 0.70714286 0.70714286]\n",
      "Mean Accuracy: 0.7050\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid_logModel_2 = [\n",
    "    {\"penalty\":[\"l2\"],\n",
    "     \"solver\":[\"sag\",\"lbfgs\",\"newton-cg\"],\n",
    "     \"tol\":[1e-4,1e-5],\n",
    "     \"max_iter\": [1000,2000]\n",
    "     }]\n",
    "logModel_tunned_2 = hyperparamaterTunning(X_uni, param_grid_logModel_2, folds, LogisticRegression(fit_intercept=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Linear SVC Models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Best Parameters: {'loss': 'squared_hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "Cross-validation Accuracies: [0.69285714 0.69285714 0.69285714 0.69285714]\n",
      "Mean Accuracy: 0.7093\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "param_grid_SVC_1 = [\n",
    "    {\"penalty\":[\"l1\",\"l2\"],\n",
    "     \"loss\": [\"squared_hinge\"],\n",
    "     \"tol\":[1e-4,1e-5],\n",
    "     \"max_iter\": [1000]\n",
    "     }]\n",
    "\n",
    "SVMModel_tunned_1 = hyperparamaterTunning(X_uni, param_grid_SVC_1, folds, LinearSVC(fit_intercept=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Best Parameters: {'loss': 'squared_hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "Cross-validation Accuracies: [0.70714286 0.70714286 0.71428571 0.71428571]\n",
      "Mean Accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "param_grid_SVC_2 = [\n",
    "    {\"penalty\":[\"l2\"],\n",
    "     \"loss\": [\"hinge\",\"squared_hinge\"],\n",
    "     \"tol\":[1e-4,1e-5],\n",
    "     \"max_iter\": [1000]\n",
    "     }]\n",
    "\n",
    "SVMModel_tunned_2 = hyperparamaterTunning(X_uni_bi, param_grid_SVC_2, folds, LinearSVC(fit_intercept=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random Forest Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid_rf = [{\n",
    "\"criterion\":[\"gini\", \"entropy\", \"log_loss\"],\n",
    "\"max_features\":[\"sqrt\", \"log2\"],\n",
    "\"max_depth\": range(10,20) # Need to look into what values to use here\n",
    "}]\n",
    "rF = hyperparamaterTunning(X_uni, param_grid_rf, folds, RandomForestClassifier())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
